{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "# from random import random\n",
    "import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : initialize network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden,n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random.random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random.random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    print(\"\",\"In my function initializa_network, there is\")\n",
    "    print(\"LAYERS i\",n_inputs,\"h\",n_hidden,\"o\",n_outputs)\n",
    "    for layer in network:\n",
    "        print(layer)\n",
    "        print(\"\")\n",
    "    \n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(weights, inputs):\n",
    "    #Add the bias weight (last index)\n",
    "\tactivation = weights[-1]\n",
    "    #Add other inputs*weights linked to our neuron\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\n",
    "\treturn activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4: Transfer neuron activation - sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(x, derivative):\n",
    "    if derivative == 0:\n",
    "        # x = activation\n",
    "        return 1.0 / (1.0 + exp(-x))\n",
    "    else:\n",
    "        # x = neuron outputs, calculate the derivative of an neuron output\n",
    "        return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 : Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, row):\n",
    "    #first input is set by the dataset array\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "        #Array of neuron value after applying activate+Transfer (for 1 layer)\n",
    "\t\tnew_inputs = []\n",
    "\n",
    "\t\tfor neuron in layer:\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "            #Add the neuron output into the neuron item (before 'weight')\n",
    "\t\t\tneuron['output'] = transfer(activation,0) # transfer = 0 to use the function 1/1+exp(x)\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\n",
    "    \n",
    "\t#returns the outputs from the last layer\n",
    "\treturn inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exerice 6 : Test forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In my function initializa_network, there is\n",
      "LAYERS i 4 h 3 o 3\n",
      "[{'weights': [0.5093199134614397, 0.5011139904329358, 0.07192563866869384, 0.7241882094088462, 0.19019775605970668]}, {'weights': [0.7039119523920881, 0.18576205796084977, 0.48440143363877886, 0.39559143402968544, 0.7227292243676652]}, {'weights': [0.5574099433621901, 0.5849131447315105, 0.8518159073308639, 0.7737953565514395, 0.8626463585913263]}]\n",
      "\n",
      "[{'weights': [0.22472584541228802, 0.19807930942645557, 0.28766247874738027, 0.021332393945312056]}, {'weights': [0.4563987431741541, 0.2474343958277858, 0.9835628305060269, 0.744521438682943]}, {'weights': [0.1407508215654023, 0.5355412750337618, 0.04699444165740363, 0.22598420123081797]}]\n",
      "\n",
      "MyNetwork is:\n",
      " [[{'weights': [0.5093199134614397, 0.5011139904329358, 0.07192563866869384, 0.7241882094088462, 0.19019775605970668]}, {'weights': [0.7039119523920881, 0.18576205796084977, 0.48440143363877886, 0.39559143402968544, 0.7227292243676652]}, {'weights': [0.5574099433621901, 0.5849131447315105, 0.8518159073308639, 0.7737953565514395, 0.8626463585913263]}], [{'weights': [0.22472584541228802, 0.19807930942645557, 0.28766247874738027, 0.021332393945312056]}, {'weights': [0.4563987431741541, 0.2474343958277858, 0.9835628305060269, 0.744521438682943]}, {'weights': [0.1407508215654023, 0.5355412750337618, 0.04699444165740363, 0.22598420123081797]}]]\n",
      "The size of the Network is 4 because there are 2 hidden layers (the 2 first) and 2 output layers (the 2 last)\n",
      "\n",
      "Test_forward_propagation:\n",
      " [0.6591829647090917, 0.9073156624049433, 0.7053408559687512]\n",
      "\n",
      "MyNetwork is, after forward propagation:\n",
      " [[{'weights': [0.5093199134614397, 0.5011139904329358, 0.07192563866869384, 0.7241882094088462, 0.19019775605970668], 'output': 0.8169220284272822}, {'weights': [0.7039119523920881, 0.18576205796084977, 0.48440143363877886, 0.39559143402968544, 0.7227292243676652], 'output': 0.9094249793695728}, {'weights': [0.5574099433621901, 0.5849131447315105, 0.8518159073308639, 0.7737953565514395, 0.8626463585913263], 'output': 0.9545951140023078}], [{'weights': [0.22472584541228802, 0.19807930942645557, 0.28766247874738027, 0.021332393945312056], 'output': 0.6591829647090917}, {'weights': [0.4563987431741541, 0.2474343958277858, 0.9835628305060269, 0.744521438682943], 'output': 0.9073156624049433}, {'weights': [0.1407508215654023, 0.5355412750337618, 0.04699444165740363, 0.22598420123081797], 'output': 0.7053408559687512}]]\n"
     ]
    }
   ],
   "source": [
    "my_Network = initialize_network(4,3,3) #nb input=4, nb hidden=3, nb output=3\n",
    "print(\"MyNetwork is:\\n\",my_Network)\n",
    "print(\"The size of the Network is 4 because there are 2 hidden layers (the 2 first) and 2 output layers (the 2 last)\")\n",
    "\n",
    "# For the row parameter you can define it by yourself. It should be a selected vectors of the\n",
    "# same size as n inputs for instance inputs = [random.randint(0, 1) for i in range(n inputs)]\n",
    "# Here the row input parameter should be a vector of size 4\n",
    "test_forward_propagation = forward_propagate(my_Network,(1,0,1,1)) #row represente my intput which will be * with the weight\n",
    "print(\"\\nTest_forward_propagation:\\n\", test_forward_propagation)\n",
    "print(\"\\nMyNetwork is, after forward propagation:\\n\", my_Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  The outputs are calculated according to the weights by passing in the functions activations and tranfere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 7 : Transfer Derivate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    derivative = output * (1.0 - output)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I choose to calcul the derivative in my function transfert, which is defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 8 : Error Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate_error (network, expected):\n",
    "    for i in reversed(range(len(network))): #Start from last layer\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        # Error computed for the hidden layers: error = (weight_k * error_j) * transfer_derivative(output)\n",
    "        if i != (len (network)-1):\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                \n",
    "                # for each neuron[LAYER N+1] linked to this neuron[LAYER N] (current layer)\n",
    "                for neuron in network [i + 1]:\n",
    "                    #error = Sum(delta * weight linked to this delta)\n",
    "                    error += (neuron ['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "\n",
    "        # Error computed for the last layer: error = (expected - output) * transfer_derivative(output)\n",
    "        else :\n",
    "            #Store the difference between expected and output for each output neuron in errors[]\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        \n",
    "        #Store the error signal in delta for each neuron\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer [j]\n",
    "            neuron ['delta'] = errors [j] * transfer_derivative(neuron['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNetwork was:\n",
      " [[{'weights': [0.5093199134614397, 0.5011139904329358, 0.07192563866869384, 0.7241882094088462, 0.19019775605970668], 'output': 0.8169220284272822}, {'weights': [0.7039119523920881, 0.18576205796084977, 0.48440143363877886, 0.39559143402968544, 0.7227292243676652], 'output': 0.9094249793695728}, {'weights': [0.5574099433621901, 0.5849131447315105, 0.8518159073308639, 0.7737953565514395, 0.8626463585913263], 'output': 0.9545951140023078}], [{'weights': [0.22472584541228802, 0.19807930942645557, 0.28766247874738027, 0.021332393945312056], 'output': 0.6591829647090917}, {'weights': [0.4563987431741541, 0.2474343958277858, 0.9835628305060269, 0.744521438682943], 'output': 0.9073156624049433}, {'weights': [0.1407508215654023, 0.5355412750337618, 0.04699444165740363, 0.22598420123081797], 'output': 0.7053408559687512}]]\n",
      "\n",
      "myNetwork is, after back propagation:\n",
      " [[{'weights': [0.5093199134614397, 0.5011139904329358, 0.07192563866869384, 0.7241882094088462, 0.19019775605970668], 'output': 0.8169220284272822, 'delta': -0.003156220483344921}, {'weights': [0.7039119523920881, 0.18576205796084977, 0.48440143363877886, 0.39559143402968544, 0.7227292243676652], 'output': 0.9094249793695728, 'delta': 0.0004440882988890574}, {'weights': [0.5574099433621901, 0.5849131447315105, 0.8518159073308639, 0.7737953565514395, 0.8626463585913263], 'output': 0.9545951140023078, 'delta': -0.0013894396279571476}], [{'weights': [0.22472584541228802, 0.19807930942645557, 0.28766247874738027, 0.021332393945312056], 'output': 0.6591829647090917, 'delta': -0.14809256148383595}, {'weights': [0.4563987431741541, 0.2474343958277858, 0.9835628305060269, 0.744521438682943], 'output': 0.9073156624049433, 'delta': 0.007794192158980636}, {'weights': [0.1407508215654023, 0.5355412750337618, 0.04699444165740363, 0.22598420123081797], 'output': 0.7053408559687512, 'delta': 0.06124052235110113}]]\n"
     ]
    }
   ],
   "source": [
    "print(\"myNetwork was:\\n\",my_Network)\n",
    "test_back_proba_error = backward_propagate_error(my_Network,(0,1,1))\n",
    "print(\"\\nmyNetwork is, after back propagation:\\n\",my_Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~ TD3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 10 : Updating weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(network, row, l_rate):\n",
    "\tfor idx_layer in range(len(network)):\n",
    "\t\tinputs = row[:-1]\n",
    "\t\t# Store the outputs of the layer N-1 into inputs[]\n",
    "\t\tif idx_layer != 0:\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[idx_layer - 1]]\n",
    "\t\t\n",
    "\t\tfor neuron in network[idx_layer]:\n",
    "            # Compute the new weights for each neuron of the layer N\n",
    "\t\t\tfor idx_input in range(len(inputs)):\n",
    "\t\t\t\t# weight = weight + learning rate * error * input\n",
    "\t\t\t\tneuron['weights'][idx_input] += l_rate * neuron['delta'] * inputs[idx_input]\n",
    "            \n",
    "            # Update the bias of the neuron (input=1 below)\n",
    "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta'] * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 11 : Train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        # Apply for each row of the dataset the backprop \n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "\t\t\t\n",
    "            # Sum_error = MSE = (1/len(expected)) * Somme(expected-output)²\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            sum_error =sum_error/len(expected)\n",
    "\n",
    "            # computing and adding delta to the network thanks to backpropagation\n",
    "            \n",
    "            # backward_propagate_error only change Delta\n",
    "            backward_propagate_error(network, expected) # here expected = (1,0) or (0,1)\n",
    "            # update_weights only change weight\n",
    "            update_weights(network, row, l_rate)\n",
    "\n",
    "            # print(\">epoch =%d, lrate =%.3f, error =%.3f\"%(epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 12 : Check the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# dataset = []\n",
    "# for i in range(10):\n",
    "#     tab = []\n",
    "#     for j in range(3):\n",
    "#         if j != 2:\n",
    "#             tab.append(random.uniform(0,10))\n",
    "#         if j == 2:\n",
    "#             tab.append(random.randint(0,1)) #It represents the index of the good one\n",
    "#     dataset.append(tab)\n",
    "# print(\"Data Test:\\n\",dataset)\n",
    "\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "\t[1.465489372,2.362125076,0],\n",
    "\t[3.396561688,4.400293529,0],\n",
    "\t[1.38807019,1.850220317,0],\n",
    "\t[3.06407232,3.005305973,0],\n",
    "\t[7.627531214,2.759262235,1],\n",
    "\t[5.332441248,2.088626775,1],\n",
    "\t[6.922596716,1.77106367,1],\n",
    "\t[8.675418651,-0.242068655,1],\n",
    "\t[7.673756466,3.508563011,1]]\n",
    "    \n",
    "n_input_test = len(dataset[0]) - 1 #2\n",
    "print(set([row[-1] for row in dataset]))#{0, 1}\n",
    "print(n_input_test)\n",
    "\n",
    "n_output_test = len(set([row[-1] for row in dataset])) # all possible classes 2\n",
    "print(n_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In my function initializa_network, there is\n",
      "LAYERS i 2 h 2 o 2\n",
      "[{'weights': [0.6258282934375422, 0.7070850532370988, 0.5507878794205968]}, {'weights': [0.022390533378049082, 0.8525756344359464, 0.8280851944893923]}]\n",
      "\n",
      "[{'weights': [0.17156005033587496, 0.7133897042426659, 0.6760830937483774]}, {'weights': [0.5720884492983356, 0.4608289570156421, 0.43341743986010595]}]\n",
      "\n",
      "\n",
      "Network layer before training:\n",
      " [[{'weights': [0.6258282934375422, 0.7070850532370988, 0.5507878794205968]}, {'weights': [0.022390533378049082, 0.8525756344359464, 0.8280851944893923]}], [{'weights': [0.17156005033587496, 0.7133897042426659, 0.6760830937483774]}, {'weights': [0.5720884492983356, 0.4608289570156421, 0.43341743986010595]}]]\n",
      "\n",
      "Network layer after training:\n",
      " [[{'weights': [0.7530609263692084, -1.0136018084671832, -0.06101248459727464], 'output': 0.891467261163549, 'delta': 0.0015427609171703742}, {'weights': [-1.9457923067572143, 2.645258170233533, 1.443963912295635], 'output': 0.014973378472957903, 'delta': -0.0005574393768984307}], [{'weights': [-1.9819722849157717, 4.476738216290099, -0.947266873119546], 'output': 0.06639668063462233, 'delta': -0.0041158081579487716}, {'weights': [1.816252143911651, -4.508003633860557, 1.071733685656327], 'output': 0.9321065094900072, 'delta': 0.00429656924025276}]]\n"
     ]
    }
   ],
   "source": [
    "my_Network_test = initialize_network(n_input_test, 2, n_output_test)\n",
    "print(\"\\nNetwork layer before training:\\n\", my_Network_test)\n",
    "train_network(my_Network_test, dataset, 0.5, 100, n_output_test) #the expected is defined above\n",
    "print(\"\\nNetwork layer after training:\\n\", my_Network_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 13 : Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTE: Since this network returns back the probability assigned to each binary output, it is better to turn the index in the network output that has the largest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the max value for each output (ex: output[i]=[0.1, 0.9, 0.2], prediciont[i] = 1)\n",
    "def predict(network, row):\n",
    "\toutputs = forward_propagate(network, row)\n",
    "\tpredictions = outputs.index(max(outputs))\n",
    "\treturn predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 14 : Test Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Consigne: Predict the labels of the same dataset used for the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = list()\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(my_Network_test, row)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "print(\"pred =\", predictions)\n",
    "\n",
    "# for row in dataset:\n",
    "#     prediction = predict(my_Network_test, row)\n",
    "#     print('Expected = %d, results = %d'%(row[-1],prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Test making predictions with the network\n",
    "network = [[{'weights': [-1.482313569067226, 1.8308790073202204, 1.078381922048799]}, {'weights': [0.23244990332399884, 0.3621998343835864, 0.40289821191094327]}],\n",
    "\t[{'weights': [2.5001872433501404, 0.7887233511355132, -1.1026649757805829]}, {'weights': [-2.429350576245497, 0.8357651039198697, 1.0699217181280656]}]]\n",
    "\n",
    "# for row in dataset:\n",
    "# \tprediction = predict(network, row)\n",
    "# \tprint('Expected=%d, results=%d' % (row[-1], prediction))\n",
    "\n",
    "predictions_2 = list()\n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(my_Network_test, row)\n",
    "    predictions_2.append(prediction)\n",
    "\n",
    "print(\"pred =\", predictions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 15 & 16 : Download & Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['15.26', '14.84', '0.871', '5.763', '3.312', '2.221', '5.22', '1'],\n",
       " ['14.88', '14.57', '0.8811', '5.554', '3.333', '1.018', '4.956', '1'],\n",
       " ['14.29', '14.09', '0.905', '5.291', '3.337', '2.699', '4.825', '1'],\n",
       " ['13.84', '13.94', '0.8955', '5.324', '3.379', '2.259', '4.805', '1'],\n",
       " ['16.14', '14.99', '0.9034', '5.658', '3.562', '1.355', '5.175', '1'],\n",
       " ['14.38', '14.21', '0.8951', '5.386', '3.312', '2.462', '4.956', '1'],\n",
       " ['14.69', '14.49', '0.8799', '5.563', '3.259', '3.586', '5.219', '1'],\n",
       " ['14.11', '14.1', '0.8911', '5.42', '3.302', '2.70', '5.00', '1'],\n",
       " ['16.63', '15.46', '0.8747', '6.053', '3.465', '2.04', '5.877', '1'],\n",
       " ['16.44', '15.25', '0.888', '5.884', '3.505', '1.969', '5.533', '1'],\n",
       " ['15.26', '14.85', '0.8696', '5.714', '3.242', '4.543', '5.314', '1'],\n",
       " ['14.03', '14.16', '0.8796', '5.438', '3.201', '1.717', '5.001', '1'],\n",
       " ['13.89', '14.02', '0.888', '5.439', '3.199', '3.986', '4.738', '1'],\n",
       " ['13.78', '14.06', '0.8759', '5.479', '3.156', '3.136', '4.872', '1'],\n",
       " ['13.74', '14.05', '0.8744', '5.482', '3.114', '2.932', '4.825', '1'],\n",
       " ['14.59', '14.28', '0.8993', '5.351', '3.333', '4.185', '4.781', '1'],\n",
       " ['13.99', '13.83', '0.9183', '5.119', '3.383', '5.234', '4.781', '1'],\n",
       " ['15.69', '14.75', '0.9058', '5.527', '3.514', '1.599', '5.046', '1'],\n",
       " ['14.7', '14.21', '0.9153', '5.205', '3.466', '1.767', '4.649', '1'],\n",
       " ['12.72', '13.57', '0.8686', '5.226', '3.049', '4.102', '4.914', '1'],\n",
       " ['14.16', '14.4', '0.8584', '5.658', '3.129', '3.072', '5.176', '1'],\n",
       " ['14.11', '14.26', '0.8722', '5.52', '3.168', '2.688', '5.219', '1'],\n",
       " ['15.88', '14.9', '0.8988', '5.618', '3.507', '0.7651', '5.091', '1'],\n",
       " ['12.08', '13.23', '0.8664', '5.099', '2.936', '1.415', '4.961', '1'],\n",
       " ['15.01', '14.76', '0.8657', '5.789', '3.245', '1.791', '5.001', '1'],\n",
       " ['16.19', '15.16', '0.8849', '5.833', '3.421', '0.903', '5.307', '1'],\n",
       " ['13.02', '13.76', '0.8641', '5.395', '3.026', '3.373', '4.825', '1'],\n",
       " ['12.74', '13.67', '0.8564', '5.395', '2.956', '2.504', '4.869', '1'],\n",
       " ['14.11', '14.18', '0.882', '5.541', '3.221', '2.754', '5.038', '1'],\n",
       " ['13.45', '14.02', '0.8604', '5.516', '3.065', '3.531', '5.097', '1'],\n",
       " ['13.16', '13.82', '0.8662', '5.454', '2.975', '0.8551', '5.056', '1'],\n",
       " ['15.49', '14.94', '0.8724', '5.757', '3.371', '3.412', '5.228', '1'],\n",
       " ['14.09', '14.41', '0.8529', '5.717', '3.186', '3.92', '5.299', '1'],\n",
       " ['13.94', '14.17', '0.8728', '5.585', '3.15', '2.124', '5.012', '1'],\n",
       " ['15.05', '14.68', '0.8779', '5.712', '3.328', '2.129', '5.36', '1'],\n",
       " ['16.12', '15.00', '0.90', '5.709', '3.485', '2.27', '5.443', '1'],\n",
       " ['16.2', '15.27', '0.8734', '5.826', '3.464', '2.823', '5.527', '1'],\n",
       " ['17.08', '15.38', '0.9079', '5.832', '3.683', '2.956', '5.484', '1'],\n",
       " ['14.8', '14.52', '0.8823', '5.656', '3.288', '3.112', '5.309', '1'],\n",
       " ['14.28', '14.17', '0.8944', '5.397', '3.298', '6.685', '5.001', '1'],\n",
       " ['13.54', '13.85', '0.8871', '5.348', '3.156', '2.587', '5.178', '1'],\n",
       " ['13.5', '13.85', '0.8852', '5.351', '3.158', '2.249', '5.176', '1'],\n",
       " ['13.16', '13.55', '0.9009', '5.138', '3.201', '2.461', '4.783', '1'],\n",
       " ['15.5', '14.86', '0.882', '5.877', '3.396', '4.711', '5.528', '1'],\n",
       " ['15.11', '14.54', '0.8986', '5.579', '3.462', '3.128', '5.18', '1'],\n",
       " ['13.8', '14.04', '0.8794', '5.376', '3.155', '1.56', '4.961', '1'],\n",
       " ['15.36', '14.76', '0.8861', '5.701', '3.393', '1.367', '5.132', '1'],\n",
       " ['14.99', '14.56', '0.8883', '5.57', '3.377', '2.958', '5.175', '1'],\n",
       " ['14.79', '14.52', '0.8819', '5.545', '3.291', '2.704', '5.111', '1'],\n",
       " ['14.86', '14.67', '0.8676', '5.678', '3.258', '2.129', '5.351', '1'],\n",
       " ['14.43', '14.4', '0.8751', '5.585', '3.272', '3.975', '5.144', '1'],\n",
       " ['15.78', '14.91', '0.8923', '5.674', '3.434', '5.593', '5.136', '1'],\n",
       " ['14.49', '14.61', '0.8538', '5.715', '3.113', '4.116', '5.396', '1'],\n",
       " ['14.33', '14.28', '0.8831', '5.504', '3.199', '3.328', '5.224', '1'],\n",
       " ['14.52', '14.6', '0.8557', '5.741', '3.113', '1.481', '5.487', '1'],\n",
       " ['15.03', '14.77', '0.8658', '5.702', '3.212', '1.933', '5.439', '1'],\n",
       " ['14.46', '14.35', '0.8818', '5.388', '3.377', '2.802', '5.044', '1'],\n",
       " ['14.92', '14.43', '0.9006', '5.384', '3.412', '1.142', '5.088', '1'],\n",
       " ['15.38', '14.77', '0.8857', '5.662', '3.419', '1.999', '5.222', '1'],\n",
       " ['12.11', '13.47', '0.8392', '5.159', '3.032', '1.502', '4.519', '1'],\n",
       " ['11.42', '12.86', '0.8683', '5.008', '2.85', '2.7', '4.607', '1'],\n",
       " ['11.23', '12.63', '0.884', '4.902', '2.879', '2.269', '4.703', '1'],\n",
       " ['12.36', '13.19', '0.8923', '5.076', '3.042', '3.22', '4.605', '1'],\n",
       " ['13.22', '13.84', '0.868', '5.395', '3.07', '4.157', '5.088', '1'],\n",
       " ['12.78', '13.57', '0.8716', '5.262', '3.026', '1.176', '4.782', '1'],\n",
       " ['12.88', '13.5', '0.8879', '5.139', '3.119', '2.352', '4.607', '1'],\n",
       " ['14.34', '14.37', '0.8726', '5.63', '3.19', '1.313', '5.15', '1'],\n",
       " ['14.01', '14.29', '0.8625', '5.609', '3.158', '2.217', '5.132', '1'],\n",
       " ['14.37', '14.39', '0.8726', '5.569', '3.153', '1.464', '5.3', '1'],\n",
       " ['12.73', '13.75', '0.8458', '5.412', '2.882', '3.533', '5.067', '1'],\n",
       " ['17.63', '15.98', '0.8673', '6.191', '3.561', '4.076', '6.06', '2'],\n",
       " ['16.84', '15.67', '0.8623', '5.998', '3.484', '4.675', '5.877', '2'],\n",
       " ['17.26', '15.73', '0.8763', '5.978', '3.594', '4.539', '5.791', '2'],\n",
       " ['19.11', '16.26', '0.9081', '6.154', '3.93', '2.936', '6.079', '2'],\n",
       " ['16.82', '15.51', '0.8786', '6.017', '3.486', '4.004', '5.841', '2'],\n",
       " ['16.77', '15.62', '0.8638', '5.927', '3.438', '4.92', '5.795', '2'],\n",
       " ['17.32', '15.91', '0.8599', '6.064', '3.403', '3.824', '5.922', '2'],\n",
       " ['20.71', '17.23', '0.8763', '6.579', '3.814', '4.451', '6.451', '2'],\n",
       " ['18.94', '16.49', '0.875', '6.445', '3.639', '5.064', '6.362', '2'],\n",
       " ['17.12', '15.55', '0.8892', '5.85', '3.566', '2.858', '5.746', '2'],\n",
       " ['16.53', '15.34', '0.8823', '5.875', '3.467', '5.532', '5.88', '2'],\n",
       " ['18.72', '16.19', '0.8977', '6.006', '3.857', '5.324', '5.879', '2'],\n",
       " ['20.2', '16.89', '0.8894', '6.285', '3.864', '5.173', '6.187', '2'],\n",
       " ['19.57', '16.74', '0.8779', '6.384', '3.772', '1.472', '6.273', '2'],\n",
       " ['19.51', '16.71', '0.878', '6.366', '3.801', '2.962', '6.185', '2'],\n",
       " ['18.27', '16.09', '0.887', '6.173', '3.651', '2.443', '6.197', '2'],\n",
       " ['18.88', '16.26', '0.8969', '6.084', '3.764', '1.649', '6.109', '2'],\n",
       " ['18.98', '16.66', '0.859', '6.549', '3.67', '3.691', '6.498', '2'],\n",
       " ['21.18', '17.21', '0.8989', '6.573', '4.033', '5.78', '6.231', '2'],\n",
       " ['20.88', '17.05', '0.9031', '6.45', '4.032', '5.016', '6.321', '2'],\n",
       " ['20.1', '16.99', '0.8746', '6.581', '3.785', '1.955', '6.449', '2'],\n",
       " ['18.76', '16.2', '0.8984', '6.172', '3.796', '3.12', '6.053', '2'],\n",
       " ['18.81', '16.29', '0.8906', '6.272', '3.693', '3.237', '6.053', '2'],\n",
       " ['18.59', '16.05', '0.9066', '6.037', '3.86', '6.001', '5.877', '2'],\n",
       " ['18.36', '16.52', '0.8452', '6.666', '3.485', '4.933', '6.448', '2'],\n",
       " ['16.87', '15.65', '0.8648', '6.139', '3.463', '3.696', '5.967', '2'],\n",
       " ['19.31', '16.59', '0.8815', '6.341', '3.81', '3.477', '6.238', '2'],\n",
       " ['18.98', '16.57', '0.8687', '6.449', '3.552', '2.144', '6.453', '2'],\n",
       " ['18.17', '16.26', '0.8637', '6.271', '3.512', '2.853', '6.273', '2'],\n",
       " ['18.72', '16.34', '0.881', '6.219', '3.684', '2.188', '6.097', '2'],\n",
       " ['16.41', '15.25', '0.8866', '5.718', '3.525', '4.217', '5.618', '2'],\n",
       " ['17.99', '15.86', '0.8992', '5.89', '3.694', '2.068', '5.837', '2'],\n",
       " ['19.46', '16.5', '0.8985', '6.113', '3.892', '4.308', '6.009', '2'],\n",
       " ['19.18', '16.63', '0.8717', '6.369', '3.681', '3.357', '6.229', '2'],\n",
       " ['18.95', '16.42', '0.8829', '6.248', '3.755', '3.368', '6.148', '2'],\n",
       " ['18.83', '16.29', '0.8917', '6.037', '3.786', '2.553', '5.879', '2'],\n",
       " ['18.85', '16.17', '0.9056', '6.152', '3.806', '2.843', '6.2', '2'],\n",
       " ['17.63', '15.86', '0.88', '6.033', '3.573', '3.747', '5.929', '2'],\n",
       " ['19.94', '16.92', '0.8752', '6.675', '3.763', '3.252', '6.55', '2'],\n",
       " ['18.55', '16.22', '0.8865', '6.153', '3.674', '1.738', '5.894', '2'],\n",
       " ['18.45', '16.12', '0.8921', '6.107', '3.769', '2.235', '5.794', '2'],\n",
       " ['19.38', '16.72', '0.8716', '6.303', '3.791', '3.678', '5.965', '2'],\n",
       " ['19.13', '16.31', '0.9035', '6.183', '3.902', '2.109', '5.924', '2'],\n",
       " ['19.14', '16.61', '0.8722', '6.259', '3.737', '6.682', '6.053', '2'],\n",
       " ['20.97', '17.25', '0.8859', '6.563', '3.991', '4.677', '6.316', '2'],\n",
       " ['19.06', '16.45', '0.8854', '6.416', '3.719', '2.248', '6.163', '2'],\n",
       " ['18.96', '16.2', '0.9077', '6.051', '3.897', '4.334', '5.75', '2'],\n",
       " ['19.15', '16.45', '0.889', '6.245', '3.815', '3.084', '6.185', '2'],\n",
       " ['18.89', '16.23', '0.9008', '6.227', '3.769', '3.639', '5.966', '2'],\n",
       " ['20.03', '16.9', '0.8811', '6.493', '3.857', '3.063', '6.32', '2'],\n",
       " ['20.24', '16.91', '0.8897', '6.315', '3.962', '5.901', '6.188', '2'],\n",
       " ['18.14', '16.12', '0.8772', '6.059', '3.563', '3.619', '6.011', '2'],\n",
       " ['16.17', '15.38', '0.8588', '5.762', '3.387', '4.286', '5.703', '2'],\n",
       " ['18.43', '15.97', '0.9077', '5.98', '3.771', '2.984', '5.905', '2'],\n",
       " ['15.99', '14.89', '0.9064', '5.363', '3.582', '3.336', '5.144', '2'],\n",
       " ['18.75', '16.18', '0.8999', '6.111', '3.869', '4.188', '5.992', '2'],\n",
       " ['18.65', '16.41', '0.8698', '6.285', '3.594', '4.391', '6.102', '2'],\n",
       " ['17.98', '15.85', '0.8993', '5.979', '3.687', '2.257', '5.919', '2'],\n",
       " ['20.16', '17.03', '0.8735', '6.513', '3.773', '1.91', '6.185', '2'],\n",
       " ['17.55', '15.66', '0.8991', '5.791', '3.69', '5.366', '5.661', '2'],\n",
       " ['18.3', '15.89', '0.9108', '5.979', '3.755', '2.837', '5.962', '2'],\n",
       " ['18.94', '16.32', '0.8942', '6.144', '3.825', '2.908', '5.949', '2'],\n",
       " ['15.38', '14.9', '0.8706', '5.884', '3.268', '4.462', '5.795', '2'],\n",
       " ['16.16', '15.33', '0.8644', '5.845', '3.395', '4.266', '5.795', '2'],\n",
       " ['15.56', '14.89', '0.8823', '5.776', '3.408', '4.972', '5.847', '2'],\n",
       " ['15.38', '14.66', '0.899', '5.477', '3.465', '3.6', '5.439', '2'],\n",
       " ['17.36', '15.76', '0.8785', '6.145', '3.574', '3.526', '5.971', '2'],\n",
       " ['15.57', '15.15', '0.8527', '5.92', '3.231', '2.64', '5.879', '2'],\n",
       " ['15.6', '15.11', '0.858', '5.832', '3.286', '2.725', '5.752', '2'],\n",
       " ['16.23', '15.18', '0.885', '5.872', '3.472', '3.769', '5.922', '2'],\n",
       " ['13.07', '13.92', '0.848', '5.472', '2.994', '5.304', '5.395', '3'],\n",
       " ['13.32', '13.94', '0.8613', '5.541', '3.073', '7.035', '5.44', '3'],\n",
       " ['13.34', '13.95', '0.862', '5.389', '3.074', '5.995', '5.307', '3'],\n",
       " ['12.22', '13.32', '0.8652', '5.224', '2.967', '5.469', '5.221', '3'],\n",
       " ['11.82', '13.4', '0.8274', '5.314', '2.777', '4.471', '5.178', '3'],\n",
       " ['11.21', '13.13', '0.8167', '5.279', '2.687', '6.169', '5.275', '3'],\n",
       " ['11.43', '13.13', '0.8335', '5.176', '2.719', '2.221', '5.132', '3'],\n",
       " ['12.49', '13.46', '0.8658', '5.267', '2.967', '4.421', '5.002', '3'],\n",
       " ['12.7', '13.71', '0.8491', '5.386', '2.911', '3.26', '5.316', '3'],\n",
       " ['10.79', '12.93', '0.8107', '5.317', '2.648', '5.462', '5.194', '3'],\n",
       " ['11.83', '13.23', '0.8496', '5.263', '2.84', '5.195', '5.307', '3'],\n",
       " ['12.01', '13.52', '0.8249', '5.405', '2.776', '6.992', '5.27', '3'],\n",
       " ['12.26', '13.6', '0.8333', '5.408', '2.833', '4.756', '5.36', '3'],\n",
       " ['11.18', '13.04', '0.8266', '5.22', '2.693', '3.332', '5.001', '3'],\n",
       " ['11.36', '13.05', '0.8382', '5.175', '2.755', '4.048', '5.263', '3'],\n",
       " ['11.19', '13.05', '0.8253', '5.25', '2.675', '5.813', '5.219', '3'],\n",
       " ['11.34', '12.87', '0.8596', '5.053', '2.849', '3.347', '5.003', '3'],\n",
       " ['12.13', '13.73', '0.8081', '5.394', '2.745', '4.825', '5.22', '3'],\n",
       " ['11.75', '13.52', '0.8082', '5.444', '2.678', '4.378', '5.31', '3'],\n",
       " ['11.49', '13.22', '0.8263', '5.304', '2.695', '5.388', '5.31', '3'],\n",
       " ['12.54', '13.67', '0.8425', '5.451', '2.879', '3.082', '5.491', '3'],\n",
       " ['12.02', '13.33', '0.8503', '5.35', '2.81', '4.271', '5.308', '3'],\n",
       " ['12.05', '13.41', '0.8416', '5.267', '2.847', '4.988', '5.046', '3'],\n",
       " ['12.55', '13.57', '0.8558', '5.333', '2.968', '4.419', '5.176', '3'],\n",
       " ['11.14', '12.79', '0.8558', '5.011', '2.794', '6.388', '5.049', '3'],\n",
       " ['12.1', '13.15', '0.8793', '5.105', '2.941', '2.201', '5.056', '3'],\n",
       " ['12.44', '13.59', '0.8462', '5.319', '2.897', '4.924', '5.27', '3'],\n",
       " ['12.15', '13.45', '0.8443', '5.417', '2.837', '3.638', '5.338', '3'],\n",
       " ['11.35', '13.12', '0.8291', '5.176', '2.668', '4.337', '5.132', '3'],\n",
       " ['11.24', '13', '0.8359', '5.09', '2.715', '3.521', '5.088', '3'],\n",
       " ['11.02', '13', '0.8189', '5.325', '2.701', '6.735', '5.163', '3'],\n",
       " ['11.55', '13.1', '0.8455', '5.167', '2.845', '6.715', '4.956', '3'],\n",
       " ['11.27', '12.97', '0.8419', '5.088', '2.763', '4.309', '5.00', '3'],\n",
       " ['11.4', '13.08', '0.8375', '5.136', '2.763', '5.588', '5.089', '3'],\n",
       " ['10.83', '12.96', '0.8099', '5.278', '2.641', '5.182', '5.185', '3'],\n",
       " ['10.8', '12.57', '0.859', '4.981', '2.821', '4.773', '5.063', '3'],\n",
       " ['11.26', '13.01', '0.8355', '5.186', '2.71', '5.335', '5.092', '3'],\n",
       " ['10.74', '12.73', '0.8329', '5.145', '2.642', '4.702', '4.963', '3'],\n",
       " ['11.48', '13.05', '0.8473', '5.18', '2.758', '5.876', '5.002', '3'],\n",
       " ['12.21', '13.47', '0.8453', '5.357', '2.893', '1.661', '5.178', '3'],\n",
       " ['11.41', '12.95', '0.856', '5.09', '2.775', '4.957', '4.825', '3'],\n",
       " ['12.46', '13.41', '0.8706', '5.236', '3.017', '4.987', '5.147', '3'],\n",
       " ['12.19', '13.36', '0.8579', '5.24', '2.909', '4.857', '5.158', '3'],\n",
       " ['11.65', '13.07', '0.8575', '5.108', '2.85', '5.209', '5.135', '3'],\n",
       " ['12.89', '13.77', '0.8541', '5.495', '3.026', '6.185', '5.316', '3'],\n",
       " ['11.56', '13.31', '0.8198', '5.363', '2.683', '4.062', '5.182', '3'],\n",
       " ['11.81', '13.45', '0.8198', '5.413', '2.716', '4.898', '5.352', '3'],\n",
       " ['10.91', '12.8', '0.8372', '5.088', '2.675', '4.179', '4.956', '3'],\n",
       " ['11.23', '12.82', '0.8594', '5.089', '2.821', '7.524', '4.957', '3'],\n",
       " ['10.59', '12.41', '0.8648', '4.899', '2.787', '4.975', '4.794', '3'],\n",
       " ['10.93', '12.8', '0.839', '5.046', '2.717', '5.398', '5.045', '3'],\n",
       " ['11.27', '12.86', '0.8563', '5.091', '2.804', '3.985', '5.001', '3'],\n",
       " ['11.87', '13.02', '0.8795', '5.132', '2.953', '3.597', '5.132', '3'],\n",
       " ['10.82', '12.83', '0.8256', '5.18', '2.63', '4.853', '5.089', '3'],\n",
       " ['12.11', '13.27', '0.8639', '5.236', '2.975', '4.132', '5.012', '3'],\n",
       " ['12.8', '13.47', '0.886', '5.16', '3.126', '4.873', '4.914', '3'],\n",
       " ['12.79', '13.53', '0.8786', '5.224', '3.054', '5.483', '4.958', '3'],\n",
       " ['13.37', '13.78', '0.8849', '5.32', '3.128', '4.67', '5.091', '3'],\n",
       " ['12.62', '13.67', '0.8481', '5.41', '2.911', '3.306', '5.231', '3'],\n",
       " ['12.76', '13.38', '0.8964', '5.073', '3.155', '2.828', '4.83', '3'],\n",
       " ['12.38', '13.44', '0.8609', '5.219', '2.989', '5.472', '5.045', '3'],\n",
       " ['12.67', '13.32', '0.8977', '4.984', '3.135', '2.3', '4.745', '3'],\n",
       " ['11.18', '12.72', '0.868', '5.009', '2.81', '4.051', '4.828', '3'],\n",
       " ['12.7', '13.41', '0.8874', '5.183', '3.091', '8.456', '5.00', '3'],\n",
       " ['12.37', '13.47', '0.8567', '5.204', '2.96', '3.919', '5.001', '3'],\n",
       " ['12.19', '13.2', '0.8783', '5.137', '2.981', '3.631', '4.87', '3'],\n",
       " ['11.23', '12.88', '0.8511', '5.14', '2.795', '4.325', '5.003', '3'],\n",
       " ['13.2', '13.66', '0.8883', '5.236', '3.232', '8.315', '5.056', '3'],\n",
       " ['11.84', '13.21', '0.8521', '5.175', '2.836', '3.598', '5.044', '3'],\n",
       " ['12.3', '13.34', '0.8684', '5.243', '2.974', '5.637', '5.063', '3']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'seeds_dataset.csv'\n",
    "dataset_seed = load_csv(filename)\n",
    "dataset_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 17 : Normalize, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column]) #.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset_seed[0])-1):\n",
    "\tstr_column_to_float(dataset_seed, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0, '2': 1, '3': 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class column to integers\n",
    "str_column_to_int(dataset_seed, len(dataset_seed[0])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10.59, 21.18],\n",
       " [12.41, 17.25],\n",
       " [0.8081, 0.9183],\n",
       " [4.899, 6.675],\n",
       " [2.63, 4.033],\n",
       " [0.7651, 8.456],\n",
       " [4.519, 6.55],\n",
       " [0, 2]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax=dataset_minmax(dataset_seed)\n",
    "minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "\tfor row in dataset:\n",
    "\t\tfor i in range(len(row)-1):\n",
    "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4409820585457979,\n",
       "  0.5020661157024793,\n",
       "  0.570780399274047,\n",
       "  0.48648648648648646,\n",
       "  0.48610121168923714,\n",
       "  0.18930164220052273,\n",
       "  0.3451501723289019,\n",
       "  0],\n",
       " [0.40509915014164316,\n",
       "  0.44628099173553726,\n",
       "  0.6624319419237747,\n",
       "  0.3688063063063065,\n",
       "  0.5010691375623664,\n",
       "  0.03288301759221938,\n",
       "  0.21516494337764666,\n",
       "  0],\n",
       " [0.3493862134088762,\n",
       "  0.3471074380165289,\n",
       "  0.8793103448275864,\n",
       "  0.22072072072072094,\n",
       "  0.50392017106201,\n",
       "  0.25145301590191005,\n",
       "  0.15066469719350079,\n",
       "  0],\n",
       " [0.3068932955618508,\n",
       "  0.31611570247933873,\n",
       "  0.7931034482758617,\n",
       "  0.23930180180180172,\n",
       "  0.5338560228082679,\n",
       "  0.19424254638598865,\n",
       "  0.14081733136386,\n",
       "  0],\n",
       " [0.5240793201133145,\n",
       "  0.5330578512396694,\n",
       "  0.8647912885662429,\n",
       "  0.4273648648648651,\n",
       "  0.6642908054169634,\n",
       "  0.076701036289641,\n",
       "  0.32299359921221066,\n",
       "  0],\n",
       " [0.3578847969782815,\n",
       "  0.37190082644628114,\n",
       "  0.7894736842105262,\n",
       "  0.2742117117117118,\n",
       "  0.48610121168923714,\n",
       "  0.22063737663992516,\n",
       "  0.21516494337764666,\n",
       "  0],\n",
       " [0.3871576959395656,\n",
       "  0.4297520661157025,\n",
       "  0.6515426497277677,\n",
       "  0.3738738738738738,\n",
       "  0.4483250178189592,\n",
       "  0.3667841214942335,\n",
       "  0.34465780403742013,\n",
       "  0],\n",
       " [0.33238904627006605,\n",
       "  0.34917355371900816,\n",
       "  0.7531760435571687,\n",
       "  0.29335585585585583,\n",
       "  0.47897362794012827,\n",
       "  0.2515830396962645,\n",
       "  0.23682914820285572,\n",
       "  0],\n",
       " [0.5703493862134088,\n",
       "  0.6301652892561985,\n",
       "  0.6043557168784031,\n",
       "  0.6497747747747749,\n",
       "  0.5951532430506056,\n",
       "  0.16576733542238234,\n",
       "  0.6686361398325947,\n",
       "  0],\n",
       " [0.5524079320113315,\n",
       "  0.5867768595041322,\n",
       "  0.7250453720508166,\n",
       "  0.5546171171171174,\n",
       "  0.6236635780470419,\n",
       "  0.15653564602322226,\n",
       "  0.4992614475627771,\n",
       "  0],\n",
       " [0.4409820585457979,\n",
       "  0.5041322314049586,\n",
       "  0.5580762250453722,\n",
       "  0.4588963963963967,\n",
       "  0.4362081254454739,\n",
       "  0.4912168926913626,\n",
       "  0.3914327917282127,\n",
       "  0],\n",
       " [0.3248347497639282,\n",
       "  0.3615702479338843,\n",
       "  0.6488203266787662,\n",
       "  0.30349099099099086,\n",
       "  0.40698503207412684,\n",
       "  0.12376964984592183,\n",
       "  0.23732151649433791,\n",
       "  0],\n",
       " [0.31161473087818703,\n",
       "  0.33264462809917344,\n",
       "  0.7250453720508166,\n",
       "  0.3040540540540541,\n",
       "  0.4055595153243049,\n",
       "  0.4187936392359803,\n",
       "  0.10782865583456443,\n",
       "  0],\n",
       " [0.30122757318224735,\n",
       "  0.340909090909091,\n",
       "  0.6152450090744102,\n",
       "  0.3265765765765766,\n",
       "  0.3749109052031362,\n",
       "  0.30827341403476843,\n",
       "  0.17380600689315598,\n",
       "  0],\n",
       " [0.2974504249291785,\n",
       "  0.3388429752066117,\n",
       "  0.6016333938294005,\n",
       "  0.3282657657657659,\n",
       "  0.344975053456878,\n",
       "  0.2817485599864776,\n",
       "  0.15066469719350079,\n",
       "  0],\n",
       " [0.3777148253068933,\n",
       "  0.3863636363636362,\n",
       "  0.8275862068965515,\n",
       "  0.2545045045045045,\n",
       "  0.5010691375623664,\n",
       "  0.44466837431249917,\n",
       "  0.12900049236829128,\n",
       "  0],\n",
       " [0.3210576015108593,\n",
       "  0.2933884297520661,\n",
       "  1.0,\n",
       "  0.12387387387387375,\n",
       "  0.5367070563079115,\n",
       "  0.5810633345902301,\n",
       "  0.12900049236829128,\n",
       "  0],\n",
       " [0.4815864022662889,\n",
       "  0.4834710743801653,\n",
       "  0.8865698729582581,\n",
       "  0.3536036036036037,\n",
       "  0.6300784034212399,\n",
       "  0.10842684211210653,\n",
       "  0.25947808961102914,\n",
       "  0],\n",
       " [0.38810198300283283,\n",
       "  0.37190082644628114,\n",
       "  0.9727767695099818,\n",
       "  0.17229729729729734,\n",
       "  0.5958660014255167,\n",
       "  0.13027083956364016,\n",
       "  0.06400787789266367,\n",
       "  0],\n",
       " [0.20113314447592076,\n",
       "  0.23966942148760334,\n",
       "  0.5490018148820328,\n",
       "  0.18412162162162163,\n",
       "  0.2986457590876692,\n",
       "  0.43387639938108685,\n",
       "  0.1944854751354011,\n",
       "  0],\n",
       " [0.3371104815864023,\n",
       "  0.4111570247933885,\n",
       "  0.45644283121597123,\n",
       "  0.4273648648648651,\n",
       "  0.35566642908054164,\n",
       "  0.29995189119608895,\n",
       "  0.32348596750369285,\n",
       "  0],\n",
       " [0.33238904627006605,\n",
       "  0.38223140495867763,\n",
       "  0.5816696914700541,\n",
       "  0.34966216216216195,\n",
       "  0.38346400570206707,\n",
       "  0.2500227541640121,\n",
       "  0.34465780403742013,\n",
       "  0],\n",
       " [0.4995278564683665,\n",
       "  0.5144628099173554,\n",
       "  0.8230490018148823,\n",
       "  0.40484234234234256,\n",
       "  0.6250890947968638,\n",
       "  0.0,\n",
       "  0.2816346627277204,\n",
       "  0],\n",
       " [0.14069877242681778,\n",
       "  0.16942148760330586,\n",
       "  0.5290381125226854,\n",
       "  0.11261261261261273,\n",
       "  0.21810406272273694,\n",
       "  0.08450246395090302,\n",
       "  0.21762678483505674,\n",
       "  0],\n",
       " [0.4173748819641171,\n",
       "  0.48553719008264457,\n",
       "  0.5226860254083485,\n",
       "  0.501126126126126,\n",
       "  0.4383464005702067,\n",
       "  0.13339141062814497,\n",
       "  0.23732151649433791,\n",
       "  0],\n",
       " [0.5288007554296508,\n",
       "  0.5681818181818182,\n",
       "  0.6969147005444647,\n",
       "  0.525900900900901,\n",
       "  0.5637918745545257,\n",
       "  0.017930281241467193,\n",
       "  0.3879862136878387,\n",
       "  0],\n",
       " [0.22946175637393765,\n",
       "  0.2789256198347107,\n",
       "  0.5081669691470051,\n",
       "  0.27927927927927904,\n",
       "  0.2822523164647183,\n",
       "  0.3390890532967534,\n",
       "  0.15066469719350079,\n",
       "  0],\n",
       " [0.2030217186024552,\n",
       "  0.26033057851239666,\n",
       "  0.43829401088929243,\n",
       "  0.27927927927927904,\n",
       "  0.23235923022095506,\n",
       "  0.22609837600280855,\n",
       "  0.17232890201870985,\n",
       "  0],\n",
       " [0.33238904627006605,\n",
       "  0.3657024793388429,\n",
       "  0.6705989110707803,\n",
       "  0.36148648648648674,\n",
       "  0.421240199572345,\n",
       "  0.25860432459140026,\n",
       "  0.25553914327917293,\n",
       "  0],\n",
       " [0.27006610009442866,\n",
       "  0.33264462809917344,\n",
       "  0.47459165154265,\n",
       "  0.34740990990990994,\n",
       "  0.3100498930862437,\n",
       "  0.35963281280474335,\n",
       "  0.2845888724766127,\n",
       "  0],\n",
       " [0.24268177525967896,\n",
       "  0.2913223140495868,\n",
       "  0.5272232304900176,\n",
       "  0.3124999999999999,\n",
       "  0.24590163934426235,\n",
       "  0.011702141491893013,\n",
       "  0.26440177252584934,\n",
       "  0],\n",
       " [0.4627006610009443,\n",
       "  0.5227272727272726,\n",
       "  0.5834845735027218,\n",
       "  0.48310810810810795,\n",
       "  0.5281539558089806,\n",
       "  0.34415998127657366,\n",
       "  0.3490891186607581,\n",
       "  0],\n",
       " [0.3305004721435316,\n",
       "  0.4132231404958678,\n",
       "  0.40653357531760403,\n",
       "  0.46058558558558543,\n",
       "  0.3962936564504632,\n",
       "  0.410212068808592,\n",
       "  0.38404726735598244,\n",
       "  0],\n",
       " [0.3163361661945231,\n",
       "  0.3636363636363636,\n",
       "  0.5871143375680581,\n",
       "  0.38626126126126126,\n",
       "  0.3706343549536706,\n",
       "  0.17668933414814916,\n",
       "  0.24273756770063984,\n",
       "  0],\n",
       " [0.4211520302171861,\n",
       "  0.46900826446280985,\n",
       "  0.6333938294010889,\n",
       "  0.4577702702702702,\n",
       "  0.49750534568781163,\n",
       "  0.17733945311992097,\n",
       "  0.4140817331363862,\n",
       "  0],\n",
       " [0.5221907459867801,\n",
       "  0.5351239669421487,\n",
       "  0.8339382940108894,\n",
       "  0.4560810810810809,\n",
       "  0.6094084105488238,\n",
       "  0.1956728081238867,\n",
       "  0.4549483013293942,\n",
       "  0],\n",
       " [0.5297450424929178,\n",
       "  0.5909090909090908,\n",
       "  0.5925589836660611,\n",
       "  0.5219594594594593,\n",
       "  0.5944404846756948,\n",
       "  0.26757596640185155,\n",
       "  0.49630723781388486,\n",
       "  0],\n",
       " [0.6128423040604343,\n",
       "  0.6136363636363638,\n",
       "  0.9056261343012707,\n",
       "  0.5253378378378378,\n",
       "  0.7505345687811829,\n",
       "  0.2848691310509824,\n",
       "  0.4751354012801576,\n",
       "  0],\n",
       " [0.3975448536355053,\n",
       "  0.4359504132231404,\n",
       "  0.6733212341197818,\n",
       "  0.4262387387387386,\n",
       "  0.4689950106913754,\n",
       "  0.3051528429702636,\n",
       "  0.38897095027080264,\n",
       "  0],\n",
       " [0.348441926345609,\n",
       "  0.3636363636363636,\n",
       "  0.7831215970961883,\n",
       "  0.28040540540540554,\n",
       "  0.4761225944404846,\n",
       "  0.7697278601984163,\n",
       "  0.23732151649433791,\n",
       "  0],\n",
       " [0.27856468366383375,\n",
       "  0.2975206611570247,\n",
       "  0.7168784029038111,\n",
       "  0.25281531531531526,\n",
       "  0.3749109052031362,\n",
       "  0.23689035093422103,\n",
       "  0.3244707040866568,\n",
       "  0],\n",
       " [0.2747875354107649,\n",
       "  0.2975206611570247,\n",
       "  0.6996370235934661,\n",
       "  0.2545045045045045,\n",
       "  0.37633642195295786,\n",
       "  0.192942308442445,\n",
       "  0.32348596750369285,\n",
       "  0],\n",
       " [0.24268177525967896,\n",
       "  0.23553719008264476,\n",
       "  0.8421052631578949,\n",
       "  0.13457207207207203,\n",
       "  0.40698503207412684,\n",
       "  0.22050735284557077,\n",
       "  0.12998522895125567,\n",
       "  0],\n",
       " [0.4636449480642115,\n",
       "  0.5061983471074378,\n",
       "  0.6705989110707803,\n",
       "  0.5506756756756755,\n",
       "  0.5459729151817532,\n",
       "  0.5130608901428962,\n",
       "  0.4967996061053666,\n",
       "  0],\n",
       " [0.4268177525967894,\n",
       "  0.440082644628099,\n",
       "  0.8212341197822136,\n",
       "  0.38288288288288275,\n",
       "  0.5930149679258732,\n",
       "  0.3072332236799335,\n",
       "  0.32545544066962073,\n",
       "  0],\n",
       " [0.30311614730878195,\n",
       "  0.33677685950413205,\n",
       "  0.6470054446460974,\n",
       "  0.2685810810810813,\n",
       "  0.37419814682822505,\n",
       "  0.10335591413228623,\n",
       "  0.21762678483505674,\n",
       "  0],\n",
       " [0.4504249291784702,\n",
       "  0.48553719008264457,\n",
       "  0.7078039927404717,\n",
       "  0.4515765765765764,\n",
       "  0.5438346400570204,\n",
       "  0.07826132182189341,\n",
       "  0.3018217626784833,\n",
       "  0],\n",
       " [0.41548630783758267,\n",
       "  0.4442148760330579,\n",
       "  0.7277676950998182,\n",
       "  0.3778153153153155,\n",
       "  0.5324305060584459,\n",
       "  0.2851291786396911,\n",
       "  0.32299359921221066,\n",
       "  0],\n",
       " [0.3966005665722379,\n",
       "  0.4359504132231404,\n",
       "  0.6696914700544465,\n",
       "  0.36373873873873874,\n",
       "  0.4711332858161082,\n",
       "  0.25210313487368197,\n",
       "  0.2914820285573608,\n",
       "  0],\n",
       " [0.40321057601510857,\n",
       "  0.4669421487603305,\n",
       "  0.5399274047186934,\n",
       "  0.4386261261261261,\n",
       "  0.4476122594440484,\n",
       "  0.17733945311992097,\n",
       "  0.40965041851304773,\n",
       "  0],\n",
       " [0.3626062322946176,\n",
       "  0.4111570247933885,\n",
       "  0.6079854809437384,\n",
       "  0.38626126126126126,\n",
       "  0.4575908766928009,\n",
       "  0.4173633774980822,\n",
       "  0.3077301821762679,\n",
       "  0],\n",
       " [0.490084985835694,\n",
       "  0.5165289256198348,\n",
       "  0.7640653357531758,\n",
       "  0.4363738738738741,\n",
       "  0.5730577334283677,\n",
       "  0.6277418767634477,\n",
       "  0.30379123584441164,\n",
       "  0],\n",
       " [0.368271954674221,\n",
       "  0.4545454545454544,\n",
       "  0.4147005444646096,\n",
       "  0.45945945945945943,\n",
       "  0.34426229508196715,\n",
       "  0.4356967325020479,\n",
       "  0.431806991629739,\n",
       "  0],\n",
       " [0.35316336166194523,\n",
       "  0.3863636363636362,\n",
       "  0.6805807622504535,\n",
       "  0.3406531531531529,\n",
       "  0.4055595153243049,\n",
       "  0.33323798255080683,\n",
       "  0.3471196454948302,\n",
       "  0],\n",
       " [0.37110481586402266,\n",
       "  0.45247933884297514,\n",
       "  0.43194192377495455,\n",
       "  0.474099099099099,\n",
       "  0.34426229508196715,\n",
       "  0.09308403437829126,\n",
       "  0.4766125061546037,\n",
       "  0],\n",
       " [0.4192634560906515,\n",
       "  0.48760330578512384,\n",
       "  0.5235934664246823,\n",
       "  0.45213963963963966,\n",
       "  0.4148253741981469,\n",
       "  0.15185478942646505,\n",
       "  0.4529788281634663,\n",
       "  0],\n",
       " [0.3654390934844194,\n",
       "  0.4008264462809916,\n",
       "  0.6687840290381126,\n",
       "  0.2753378378378378,\n",
       "  0.5324305060584459,\n",
       "  0.2648454667204099,\n",
       "  0.25849335302806475,\n",
       "  0],\n",
       " [0.408876298394712,\n",
       "  0.4173553719008264,\n",
       "  0.8393829401088925,\n",
       "  0.2730855855855858,\n",
       "  0.5573770491803277,\n",
       "  0.04900596809216086,\n",
       "  0.2801575578532743,\n",
       "  0],\n",
       " [0.4523135033050048,\n",
       "  0.48760330578512384,\n",
       "  0.7041742286751363,\n",
       "  0.4296171171171171,\n",
       "  0.5623663578047041,\n",
       "  0.1604363598538533,\n",
       "  0.34613490891186627,\n",
       "  0],\n",
       " [0.14353163361661941,\n",
       "  0.21900826446281002,\n",
       "  0.28221415607985406,\n",
       "  0.1463963963963963,\n",
       "  0.28652886671418387,\n",
       "  0.09581453405973295,\n",
       "  0.0,\n",
       "  0],\n",
       " [0.07837582625118036,\n",
       "  0.0929752066115701,\n",
       "  0.5462794918330303,\n",
       "  0.06137387387387387,\n",
       "  0.15680684248039922,\n",
       "  0.2515830396962645,\n",
       "  0.04332840965041856,\n",
       "  0],\n",
       " [0.06043437204910298,\n",
       "  0.04545454545454559,\n",
       "  0.688747731397459,\n",
       "  0.0016891891891892535,\n",
       "  0.17747683535281542,\n",
       "  0.19554278432953234,\n",
       "  0.09059576563269335,\n",
       "  0],\n",
       " [0.16713881019830024,\n",
       "  0.1611570247933883,\n",
       "  0.7640653357531758,\n",
       "  0.09966216216216195,\n",
       "  0.2936564504632928,\n",
       "  0.31919541276053526,\n",
       "  0.04234367306745461,\n",
       "  0],\n",
       " [0.2483474976392824,\n",
       "  0.2954545454545454,\n",
       "  0.5435571687840288,\n",
       "  0.27927927927927904,\n",
       "  0.31361368496079817,\n",
       "  0.441027708070577,\n",
       "  0.2801575578532743,\n",
       "  0],\n",
       " [0.20679886685552404,\n",
       "  0.23966942148760334,\n",
       "  0.576225045372051,\n",
       "  0.20439189189189166,\n",
       "  0.2822523164647183,\n",
       "  0.053426777100209336,\n",
       "  0.12949286065977347,\n",
       "  0],\n",
       " [0.2162417374881965,\n",
       "  0.2252066115702479,\n",
       "  0.7241379310344829,\n",
       "  0.13513513513513528,\n",
       "  0.34853884533143276,\n",
       "  0.20633475926094477,\n",
       "  0.04332840965041856,\n",
       "  0],\n",
       " [0.35410764872521244,\n",
       "  0.40495867768595023,\n",
       "  0.5852994555353904,\n",
       "  0.4115990990990991,\n",
       "  0.3991446899501068,\n",
       "  0.0712400369267576,\n",
       "  0.3106843919251602,\n",
       "  0],\n",
       " [0.32294617563739375,\n",
       "  0.3884297520661155,\n",
       "  0.4936479128856626,\n",
       "  0.3997747747747748,\n",
       "  0.37633642195295786,\n",
       "  0.18878154702310526,\n",
       "  0.3018217626784833,\n",
       "  0],\n",
       " [0.3569405099150141,\n",
       "  0.40909090909090917,\n",
       "  0.5852994555353904,\n",
       "  0.37725225225225223,\n",
       "  0.3727726300784034,\n",
       "  0.09087362987426699,\n",
       "  0.3845396356474642,\n",
       "  0],\n",
       " [0.20207743153918797,\n",
       "  0.27685950413223137,\n",
       "  0.34210526315789447,\n",
       "  0.2888513513513513,\n",
       "  0.17961511047754822,\n",
       "  0.35989286039345203,\n",
       "  0.2698178237321517,\n",
       "  0],\n",
       " [0.6647780925401321,\n",
       "  0.737603305785124,\n",
       "  0.5372050816696909,\n",
       "  0.7274774774774775,\n",
       "  0.6635780470420526,\n",
       "  0.4304957807278732,\n",
       "  0.7587395371738058,\n",
       "  1],\n",
       " [0.5901794145420208,\n",
       "  0.6735537190082644,\n",
       "  0.49183303085299396,\n",
       "  0.6188063063063065,\n",
       "  0.6086956521739129,\n",
       "  0.508380033546139,\n",
       "  0.6686361398325947,\n",
       "  1],\n",
       " [0.6298394711992448,\n",
       "  0.6859504132231405,\n",
       "  0.6188747731397455,\n",
       "  0.6075450450450449,\n",
       "  0.6870990734141124,\n",
       "  0.49069679751394507,\n",
       "  0.6262924667651405,\n",
       "  1],\n",
       " [0.8045325779036827,\n",
       "  0.7954545454545457,\n",
       "  0.9074410163339384,\n",
       "  0.7066441441441441,\n",
       "  0.9265858873841767,\n",
       "  0.28226865516389504,\n",
       "  0.7680945347119644,\n",
       "  1],\n",
       " [0.5882908404154864,\n",
       "  0.640495867768595,\n",
       "  0.6397459165154268,\n",
       "  0.6295045045045048,\n",
       "  0.6101211689237349,\n",
       "  0.4211340675343588,\n",
       "  0.6509108813392419,\n",
       "  1],\n",
       " [0.5835694050991501,\n",
       "  0.6632231404958676,\n",
       "  0.5054446460980035,\n",
       "  0.5788288288288287,\n",
       "  0.5759087669280114,\n",
       "  0.5402358631629588,\n",
       "  0.6282619399310684,\n",
       "  1],\n",
       " [0.635505193578848,\n",
       "  0.7231404958677686,\n",
       "  0.4700544464609798,\n",
       "  0.6559684684684686,\n",
       "  0.5509622238061296,\n",
       "  0.3977297845505728,\n",
       "  0.690792712949286,\n",
       "  1],\n",
       " [0.9556185080264401,\n",
       "  0.9958677685950414,\n",
       "  0.6188747731397455,\n",
       "  0.9459459459459459,\n",
       "  0.8439059158945116,\n",
       "  0.4792547036107608,\n",
       "  0.9512555391432791,\n",
       "  1],\n",
       " [0.7884796978281399,\n",
       "  0.8429752066115699,\n",
       "  0.6070780399274045,\n",
       "  0.8704954954954958,\n",
       "  0.719173200285103,\n",
       "  0.5589592895499876,\n",
       "  0.9074347612013788,\n",
       "  1],\n",
       " [0.6166194523135035,\n",
       "  0.6487603305785126,\n",
       "  0.7359346642468237,\n",
       "  0.5354729729729728,\n",
       "  0.667141838916607,\n",
       "  0.2721267992042544,\n",
       "  0.6041358936484493,\n",
       "  1],\n",
       " [0.5609065155807367,\n",
       "  0.6053719008264462,\n",
       "  0.6733212341197818,\n",
       "  0.5495495495495496,\n",
       "  0.5965787598004276,\n",
       "  0.6198104253078314,\n",
       "  0.6701132447070408,\n",
       "  1],\n",
       " [0.7677053824362605,\n",
       "  0.7809917355371904,\n",
       "  0.8130671506352091,\n",
       "  0.623310810810811,\n",
       "  0.8745545260156806,\n",
       "  0.592765476082123,\n",
       "  0.6696208764155587,\n",
       "  1],\n",
       " [0.9074598677998111,\n",
       "  0.9256198347107439,\n",
       "  0.7377495462794914,\n",
       "  0.7804054054054056,\n",
       "  0.8795438346400567,\n",
       "  0.5731318831346136,\n",
       "  0.8212703101920238,\n",
       "  1],\n",
       " [0.8479697828139755,\n",
       "  0.8946280991735533,\n",
       "  0.6333938294010889,\n",
       "  0.8361486486486489,\n",
       "  0.8139700641482533,\n",
       "  0.09191382022910193,\n",
       "  0.863613983259478,\n",
       "  1],\n",
       " [0.8423040604343722,\n",
       "  0.8884297520661159,\n",
       "  0.6343012704174227,\n",
       "  0.8260135135135134,\n",
       "  0.8346400570206699,\n",
       "  0.2856492738171086,\n",
       "  0.8202855736090594,\n",
       "  1],\n",
       " [0.7252124645892352,\n",
       "  0.7603305785123966,\n",
       "  0.7159709618874772,\n",
       "  0.7173423423423424,\n",
       "  0.7277263007840339,\n",
       "  0.2181669245471922,\n",
       "  0.826193993106844,\n",
       "  1],\n",
       " [0.7828139754485363,\n",
       "  0.7954545454545457,\n",
       "  0.8058076225045374,\n",
       "  0.6672297297297296,\n",
       "  0.8082679971489661,\n",
       "  0.11492803182982488,\n",
       "  0.7828655834564254,\n",
       "  1],\n",
       " [0.7922568460812087,\n",
       "  0.878099173553719,\n",
       "  0.4618874773139742,\n",
       "  0.9290540540540544,\n",
       "  0.7412687099073412,\n",
       "  0.380436619901442,\n",
       "  0.9743968488429348,\n",
       "  1],\n",
       " [1.0,\n",
       "  0.9917355371900828,\n",
       "  0.8239564428312162,\n",
       "  0.9425675675675679,\n",
       "  1.0,\n",
       "  0.6520563263077144,\n",
       "  0.8429345150172329,\n",
       "  1],\n",
       " [0.971671388101983,\n",
       "  0.9586776859504134,\n",
       "  0.8620689655172414,\n",
       "  0.873310810810811,\n",
       "  0.9992872416250889,\n",
       "  0.552718147420978,\n",
       "  0.8872476612506154,\n",
       "  1],\n",
       " [0.898016997167139,\n",
       "  0.9462809917355368,\n",
       "  0.6034482758620692,\n",
       "  0.9470720720720724,\n",
       "  0.8232359230220954,\n",
       "  0.15471531290226115,\n",
       "  0.9502708025603152,\n",
       "  1],\n",
       " [0.7714825306893297,\n",
       "  0.7830578512396693,\n",
       "  0.819419237749546,\n",
       "  0.7167792792792792,\n",
       "  0.8310762651461151,\n",
       "  0.30619303332509856,\n",
       "  0.7552929591334319,\n",
       "  1],\n",
       " [0.7762039660056657,\n",
       "  0.8016528925619832,\n",
       "  0.7486388384754985,\n",
       "  0.7730855855855858,\n",
       "  0.7576621525302921,\n",
       "  0.32140581726455947,\n",
       "  0.7552929591334319,\n",
       "  1],\n",
       " [0.7554296506137866,\n",
       "  0.7520661157024795,\n",
       "  0.8938294010889288,\n",
       "  0.6407657657657658,\n",
       "  0.8766928011404131,\n",
       "  0.6807915848600294,\n",
       "  0.6686361398325947,\n",
       "  1],\n",
       " [0.7337110481586402,\n",
       "  0.8491735537190082,\n",
       "  0.3366606170598904,\n",
       "  0.9949324324324328,\n",
       "  0.6094084105488238,\n",
       "  0.5419261724895655,\n",
       "  0.9497784342688333,\n",
       "  1],\n",
       " [0.5930122757318226,\n",
       "  0.6694214876033059,\n",
       "  0.514519056261343,\n",
       "  0.6981981981981984,\n",
       "  0.593727726300784,\n",
       "  0.38108673887321387,\n",
       "  0.7129492860659772,\n",
       "  1],\n",
       " [0.8234183191690273,\n",
       "  0.8636363636363636,\n",
       "  0.6660617059891101,\n",
       "  0.8119369369369371,\n",
       "  0.8410548823948679,\n",
       "  0.3526115279096075,\n",
       "  0.8463810930576073,\n",
       "  1],\n",
       " [0.7922568460812087,\n",
       "  0.859504132231405,\n",
       "  0.5499092558983667,\n",
       "  0.8727477477477478,\n",
       "  0.6571632216678545,\n",
       "  0.1792898100352365,\n",
       "  0.9522402757262435,\n",
       "  1],\n",
       " [0.715769593956563,\n",
       "  0.7954545454545457,\n",
       "  0.5045372050816697,\n",
       "  0.7725225225225225,\n",
       "  0.6286528866714183,\n",
       "  0.2714766802324826,\n",
       "  0.863613983259478,\n",
       "  1],\n",
       " [0.7677053824362605,\n",
       "  0.8119834710743802,\n",
       "  0.6615245009074409,\n",
       "  0.7432432432432435,\n",
       "  0.751247327156094,\n",
       "  0.18501085698682865,\n",
       "  0.7769571639586413,\n",
       "  1],\n",
       " [0.5495750708215298,\n",
       "  0.5867768595041322,\n",
       "  0.7123411978221419,\n",
       "  0.4611486486486487,\n",
       "  0.63791874554526,\n",
       "  0.44882913573183897,\n",
       "  0.5411127523387496,\n",
       "  1],\n",
       " [0.6987724268177524,\n",
       "  0.7128099173553718,\n",
       "  0.8266787658802177,\n",
       "  0.5579954954954953,\n",
       "  0.7583749109052029,\n",
       "  0.1694080016643046,\n",
       "  0.6489414081733136,\n",
       "  1],\n",
       " [0.8375826251180359,\n",
       "  0.8450413223140496,\n",
       "  0.8203266787658798,\n",
       "  0.6835585585585588,\n",
       "  0.8995010691375621,\n",
       "  0.46066130101808633,\n",
       "  0.7336287543082227,\n",
       "  1],\n",
       " [0.8111425873465533,\n",
       "  0.8719008264462808,\n",
       "  0.5771324863883849,\n",
       "  0.8277027027027026,\n",
       "  0.7491090520313612,\n",
       "  0.3370086725870835,\n",
       "  0.841949778434269,\n",
       "  1],\n",
       " [0.789423984891407,\n",
       "  0.8285123966942152,\n",
       "  0.6787658802177858,\n",
       "  0.7595720720720722,\n",
       "  0.8018531717747681,\n",
       "  0.3384389343249815,\n",
       "  0.8020679468242244,\n",
       "  1],\n",
       " [0.7780925401322001,\n",
       "  0.8016528925619832,\n",
       "  0.7586206896551727,\n",
       "  0.6407657657657658,\n",
       "  0.8239486813970063,\n",
       "  0.23246954192617253,\n",
       "  0.6696208764155587,\n",
       "  1],\n",
       " [0.7799811142587348,\n",
       "  0.7768595041322317,\n",
       "  0.8847549909255894,\n",
       "  0.7055180180180182,\n",
       "  0.8382038488952244,\n",
       "  0.2701764422889389,\n",
       "  0.8276710979812901,\n",
       "  1],\n",
       " [0.6647780925401321,\n",
       "  0.7128099173553718,\n",
       "  0.6524500907441015,\n",
       "  0.6385135135135138,\n",
       "  0.6721311475409835,\n",
       "  0.38771795238528656,\n",
       "  0.6942392909896604,\n",
       "  1],\n",
       " [0.8829084041548633,\n",
       "  0.9318181818181822,\n",
       "  0.6088929219600723,\n",
       "  1.0,\n",
       "  0.8075552387740553,\n",
       "  0.32335617417987494,\n",
       "  1.0,\n",
       "  1],\n",
       " [0.7516525023607178,\n",
       "  0.7871900826446279,\n",
       "  0.7114337568058071,\n",
       "  0.7060810810810809,\n",
       "  0.7441197434069848,\n",
       "  0.12650014952736352,\n",
       "  0.6770064007877894,\n",
       "  1],\n",
       " [0.7422096317280453,\n",
       "  0.7665289256198349,\n",
       "  0.762250453720508,\n",
       "  0.6801801801801803,\n",
       "  0.8118317890235209,\n",
       "  0.19112197532148384,\n",
       "  0.6277695716395862,\n",
       "  1],\n",
       " [0.8300283286118979,\n",
       "  0.8904958677685948,\n",
       "  0.576225045372051,\n",
       "  0.7905405405405406,\n",
       "  0.8275124732715606,\n",
       "  0.37874631057483527,\n",
       "  0.7119645494830132,\n",
       "  1],\n",
       " [0.8064211520302171,\n",
       "  0.8057851239669419,\n",
       "  0.8656987295825768,\n",
       "  0.7229729729729729,\n",
       "  0.9066286528866713,\n",
       "  0.17473897723283363,\n",
       "  0.6917774495322504,\n",
       "  1],\n",
       " [0.8073654390934845,\n",
       "  0.8677685950413222,\n",
       "  0.5816696914700541,\n",
       "  0.765765765765766,\n",
       "  0.789023521026372,\n",
       "  0.7693377888153533,\n",
       "  0.7552929591334319,\n",
       "  1],\n",
       " [0.980169971671388,\n",
       "  1.0,\n",
       "  0.705989110707804,\n",
       "  0.9369369369369369,\n",
       "  0.9700641482537418,\n",
       "  0.5086400811348477,\n",
       "  0.8847858197932053,\n",
       "  1],\n",
       " [0.7998111425873464,\n",
       "  0.8347107438016528,\n",
       "  0.7014519056261338,\n",
       "  0.854166666666667,\n",
       "  0.7761938702779755,\n",
       "  0.19281228464809066,\n",
       "  0.8094534711964552,\n",
       "  1],\n",
       " [0.7903682719546743,\n",
       "  0.7830578512396693,\n",
       "  0.903811252268602,\n",
       "  0.6486486486486488,\n",
       "  0.9030648610121165,\n",
       "  0.4640419196712999,\n",
       "  0.6061053668143772,\n",
       "  1],\n",
       " [0.8083097261567516,\n",
       "  0.8347107438016528,\n",
       "  0.7341197822141561,\n",
       "  0.757882882882883,\n",
       "  0.8446186742694224,\n",
       "  0.30151217672834135,\n",
       "  0.8202855736090594,\n",
       "  1],\n",
       " [0.7837582625118037,\n",
       "  0.7892561983471075,\n",
       "  0.8411978221415611,\n",
       "  0.747747747747748,\n",
       "  0.8118317890235209,\n",
       "  0.3736753825950149,\n",
       "  0.7124569177744955,\n",
       "  1],\n",
       " [0.8914069877242683,\n",
       "  0.9276859504132229,\n",
       "  0.6624319419237747,\n",
       "  0.8975225225225228,\n",
       "  0.8745545260156806,\n",
       "  0.2987816770468997,\n",
       "  0.8867552929591337,\n",
       "  1],\n",
       " [0.91123701605288,\n",
       "  0.9297520661157025,\n",
       "  0.740471869328494,\n",
       "  0.7972972972972976,\n",
       "  0.9493941553813257,\n",
       "  0.6677892054245927,\n",
       "  0.8217626784835056,\n",
       "  1],\n",
       " [0.7129367327667612,\n",
       "  0.7665289256198349,\n",
       "  0.627041742286751,\n",
       "  0.6531531531531533,\n",
       "  0.6650035637918745,\n",
       "  0.37107490670792764,\n",
       "  0.7346134908911867,\n",
       "  1],\n",
       " [0.5269121813031163,\n",
       "  0.6136363636363638,\n",
       "  0.46007259528130656,\n",
       "  0.4859234234234232,\n",
       "  0.5395580898075552,\n",
       "  0.45780077754229026,\n",
       "  0.582964057114722,\n",
       "  1],\n",
       " [0.7403210576015109,\n",
       "  0.7355371900826447,\n",
       "  0.903811252268602,\n",
       "  0.6086711711711714,\n",
       "  0.8132573057733425,\n",
       "  0.28850979729290466,\n",
       "  0.6824224519940918,\n",
       "  1],\n",
       " [0.509915014164306,\n",
       "  0.5123966942148761,\n",
       "  0.8920145190562611,\n",
       "  0.26126126126126153,\n",
       "  0.6785459729151815,\n",
       "  0.33427817290564177,\n",
       "  0.3077301821762679,\n",
       "  1],\n",
       " [0.7705382436260624,\n",
       "  0.7789256198347106,\n",
       "  0.8330308529945556,\n",
       "  0.6824324324324323,\n",
       "  0.8831076265146115,\n",
       "  0.4450584456955623,\n",
       "  0.725258493353028,\n",
       "  1],\n",
       " [0.7610953729933899,\n",
       "  0.8264462809917356,\n",
       "  0.5598911070780399,\n",
       "  0.7804054054054056,\n",
       "  0.6870990734141124,\n",
       "  0.4714532759494988,\n",
       "  0.7794190054160515,\n",
       "  1],\n",
       " [0.6978281397544854,\n",
       "  0.7107438016528925,\n",
       "  0.8275862068965515,\n",
       "  0.6081081081081082,\n",
       "  0.7533856022808265,\n",
       "  0.19398249879727994,\n",
       "  0.6893156080748398,\n",
       "  1],\n",
       " [0.9036827195467423,\n",
       "  0.9545454545454548,\n",
       "  0.593466424682396,\n",
       "  0.9087837837837838,\n",
       "  0.8146828225231646,\n",
       "  0.1488642421563146,\n",
       "  0.8202855736090594,\n",
       "  1],\n",
       " [0.6572237960339944,\n",
       "  0.6714876033057852,\n",
       "  0.8257713248638838,\n",
       "  0.5022522522522525,\n",
       "  0.7555238774055593,\n",
       "  0.5982264754450064,\n",
       "  0.5622845888724765,\n",
       "  1],\n",
       " [0.7280453257790369,\n",
       "  0.7190082644628101,\n",
       "  0.931941923774955,\n",
       "  0.6081081081081082,\n",
       "  0.8018531717747681,\n",
       "  0.26939629952281274,\n",
       "  0.7104874446085672,\n",
       "  1],\n",
       " [0.7884796978281399,\n",
       "  0.8078512396694215,\n",
       "  0.7813067150635207,\n",
       "  0.7010135135135136,\n",
       "  0.8517462580185317,\n",
       "  0.27862798892197277,\n",
       "  0.7040866568193008,\n",
       "  1],\n",
       " [0.4523135033050048,\n",
       "  0.5144628099173554,\n",
       "  0.5671506352087116,\n",
       "  0.5546171171171174,\n",
       "  0.4547398431931573,\n",
       "  0.48068496534865884,\n",
       "  0.6282619399310684,\n",
       "  1],\n",
       " [0.5259678942398489,\n",
       "  0.6033057851239669,\n",
       "  0.5108892921960065,\n",
       "  0.5326576576576576,\n",
       "  0.5452601568068424,\n",
       "  0.455200301655203,\n",
       "  0.6282619399310684,\n",
       "  1],\n",
       " [0.46931067044381497,\n",
       "  0.5123966942148761,\n",
       "  0.6733212341197818,\n",
       "  0.49380630630630623,\n",
       "  0.554526015680684,\n",
       "  0.546997100469386,\n",
       "  0.6538650910881342,\n",
       "  1],\n",
       " [0.4523135033050048,\n",
       "  0.46487603305785125,\n",
       "  0.82486388384755,\n",
       "  0.3254504504504506,\n",
       "  0.5951532430506056,\n",
       "  0.36860445461519464,\n",
       "  0.4529788281634663,\n",
       "  1],\n",
       " [0.6392823418319169,\n",
       "  0.6921487603305785,\n",
       "  0.6388384754990919,\n",
       "  0.7015765765765763,\n",
       "  0.6728439059158943,\n",
       "  0.35898269383297143,\n",
       "  0.7149187592319055,\n",
       "  1],\n",
       " [0.4702549575070822,\n",
       "  0.566115702479339,\n",
       "  0.40471869328493637,\n",
       "  0.5748873873873874,\n",
       "  0.42836778332145387,\n",
       "  0.24378161203500245,\n",
       "  0.6696208764155587,\n",
       "  1],\n",
       " [0.4730878186968838,\n",
       "  0.5578512396694214,\n",
       "  0.45281306715063485,\n",
       "  0.5253378378378378,\n",
       "  0.4675694939415538,\n",
       "  0.25483363455512364,\n",
       "  0.6070901033973412,\n",
       "  1],\n",
       " [0.5325779036827196,\n",
       "  0.5723140495867768,\n",
       "  0.6978221415607985,\n",
       "  0.5478603603603603,\n",
       "  0.600142551674982,\n",
       "  0.39057847586108263,\n",
       "  0.690792712949286,\n",
       "  1],\n",
       " [0.23418319169027388,\n",
       "  0.3119834710743801,\n",
       "  0.36206896551724094,\n",
       "  0.3226351351351354,\n",
       "  0.25944404846756963,\n",
       "  0.5901650001950357,\n",
       "  0.4313146233382568,\n",
       "  2],\n",
       " [0.25779036827195473,\n",
       "  0.31611570247933873,\n",
       "  0.4827586206896545,\n",
       "  0.36148648648648674,\n",
       "  0.31575196008553097,\n",
       "  0.8152361882224448,\n",
       "  0.4534711964549485,\n",
       "  2],\n",
       " [0.25967894239848915,\n",
       "  0.318181818181818,\n",
       "  0.4891107078039924,\n",
       "  0.275900900900901,\n",
       "  0.3164647184604418,\n",
       "  0.6800114420939032,\n",
       "  0.3879862136878387,\n",
       "  2],\n",
       " [0.1539187913125591,\n",
       "  0.18801652892561987,\n",
       "  0.5181488203266783,\n",
       "  0.18299549549549562,\n",
       "  0.2401995723449751,\n",
       "  0.6116189262635063,\n",
       "  0.3456425406203841,\n",
       "  2],\n",
       " [0.11614730878186973,\n",
       "  0.20454545454545459,\n",
       "  0.17513611615245,\n",
       "  0.23367117117117123,\n",
       "  0.1047754811119032,\n",
       "  0.4818551794978482,\n",
       "  0.3244707040866568,\n",
       "  2],\n",
       " [0.05854579792256855,\n",
       "  0.14876033057851254,\n",
       "  0.07803992740471818,\n",
       "  0.21396396396396392,\n",
       "  0.04062722736992154,\n",
       "  0.702635582311563,\n",
       "  0.37223042836041376,\n",
       "  2],\n",
       " [0.07932011331444758,\n",
       "  0.14876033057851254,\n",
       "  0.2304900181488202,\n",
       "  0.15596846846846857,\n",
       "  0.06343549536707052,\n",
       "  0.18930164220052273,\n",
       "  0.3018217626784833,\n",
       "  2],\n",
       " [0.17941454202077436,\n",
       "  0.21694214876033074,\n",
       "  0.5235934664246823,\n",
       "  0.20720720720720742,\n",
       "  0.2401995723449751,\n",
       "  0.4753539897801299,\n",
       "  0.23781388478581966,\n",
       "  2],\n",
       " [0.19924457034938617,\n",
       "  0.2685950413223142,\n",
       "  0.37205081669691414,\n",
       "  0.2742117117117118,\n",
       "  0.20028510334996438,\n",
       "  0.3243963645347099,\n",
       "  0.39241752831117666,\n",
       "  2],\n",
       " [0.018885741265344598,\n",
       "  0.10743801652892554,\n",
       "  0.02359346642468182,\n",
       "  0.23536036036036048,\n",
       "  0.012829650748396459,\n",
       "  0.6107087597030256,\n",
       "  0.33234859675036926,\n",
       "  2],\n",
       " [0.11709159584513694,\n",
       "  0.16942148760330586,\n",
       "  0.37658802177858436,\n",
       "  0.20495495495495492,\n",
       "  0.14967925873129,\n",
       "  0.5759924066104097,\n",
       "  0.3879862136878387,\n",
       "  2],\n",
       " [0.13408876298394712,\n",
       "  0.2293388429752065,\n",
       "  0.152450090744101,\n",
       "  0.28490990990991005,\n",
       "  0.10406272273699206,\n",
       "  0.809645165065207,\n",
       "  0.36976858690300324,\n",
       "  2],\n",
       " [0.15769593956562794,\n",
       "  0.24586776859504123,\n",
       "  0.22867513611615253,\n",
       "  0.2865990990990993,\n",
       "  0.1446899501069139,\n",
       "  0.5189119608888427,\n",
       "  0.4140817331363862,\n",
       "  2],\n",
       " [0.05571293673276675,\n",
       "  0.13016528925619814,\n",
       "  0.1678765880217783,\n",
       "  0.18074324324324312,\n",
       "  0.04490377761938713,\n",
       "  0.3337580777282243,\n",
       "  0.23732151649433791,\n",
       "  2],\n",
       " [0.07271010387157692,\n",
       "  0.1322314049586778,\n",
       "  0.27313974591651463,\n",
       "  0.15540540540540532,\n",
       "  0.08909479686386312,\n",
       "  0.426855114485951,\n",
       "  0.36632200886262917,\n",
       "  2],\n",
       " [0.05665722379603396,\n",
       "  0.1322314049586778,\n",
       "  0.15607985480943737,\n",
       "  0.19763513513513514,\n",
       "  0.03207412687099067,\n",
       "  0.6563471115214085,\n",
       "  0.34465780403742013,\n",
       "  2],\n",
       " [0.0708215297450425,\n",
       "  0.0950413223140494,\n",
       "  0.4673321234119783,\n",
       "  0.08671171171171167,\n",
       "  0.15609408410548842,\n",
       "  0.33570843464353983,\n",
       "  0.23830625307730186,\n",
       "  2],\n",
       " [0.145420207743154,\n",
       "  0.2727272727272728,\n",
       "  0.0,\n",
       "  0.2787162162162163,\n",
       "  0.08196721311475422,\n",
       "  0.527883602699294,\n",
       "  0.3451501723289019,\n",
       "  2],\n",
       " [0.10953729933899907,\n",
       "  0.2293388429752065,\n",
       "  0.0009074410163338386,\n",
       "  0.30686936936936937,\n",
       "  0.034212401995723465,\n",
       "  0.4697629666228921,\n",
       "  0.3894633185622844,\n",
       "  2],\n",
       " [0.08498583569405102,\n",
       "  0.16735537190082656,\n",
       "  0.16515426497277677,\n",
       "  0.2280405405405407,\n",
       "  0.04632929436920878,\n",
       "  0.6010869989208025,\n",
       "  0.3894633185622844,\n",
       "  2],\n",
       " [0.18413597733711043,\n",
       "  0.26033057851239666,\n",
       "  0.31215970961887474,\n",
       "  0.31081081081081063,\n",
       "  0.17747683535281542,\n",
       "  0.30125212913963256,\n",
       "  0.4785819793205316,\n",
       "  2],\n",
       " [0.13503305004721433,\n",
       "  0.19008264462809915,\n",
       "  0.38294010889292124,\n",
       "  0.25394144144144126,\n",
       "  0.128296507483963,\n",
       "  0.4558504206269748,\n",
       "  0.38847858197932045,\n",
       "  2],\n",
       " [0.13786591123701614,\n",
       "  0.2066115702479339,\n",
       "  0.3039927404718692,\n",
       "  0.20720720720720742,\n",
       "  0.15466856735566645,\n",
       "  0.5490774811790559,\n",
       "  0.25947808961102914,\n",
       "  2],\n",
       " [0.1850802644003778,\n",
       "  0.23966942148760334,\n",
       "  0.4328493647912884,\n",
       "  0.24436936936936948,\n",
       "  0.24091233071988594,\n",
       "  0.47509394219142104,\n",
       "  0.32348596750369285,\n",
       "  2],\n",
       " [0.051935788479697896,\n",
       "  0.07851239669421467,\n",
       "  0.4328493647912884,\n",
       "  0.06306306306306313,\n",
       "  0.11689237348538851,\n",
       "  0.7311107932751694,\n",
       "  0.2609551944854753,\n",
       "  2],\n",
       " [0.1425873465533522,\n",
       "  0.15289256198347112,\n",
       "  0.6460980036297637,\n",
       "  0.11599099099099124,\n",
       "  0.2216678545972914,\n",
       "  0.1867011663134354,\n",
       "  0.26440177252584934,\n",
       "  2],\n",
       " [0.1746931067044381,\n",
       "  0.24380165289256192,\n",
       "  0.3457350272232298,\n",
       "  0.23648648648648649,\n",
       "  0.19030648610121156,\n",
       "  0.5407559583403764,\n",
       "  0.36976858690300324,\n",
       "  2],\n",
       " [0.14730878186968843,\n",
       "  0.21487603305785108,\n",
       "  0.3284936479128859,\n",
       "  0.2916666666666666,\n",
       "  0.14754098360655754,\n",
       "  0.3735453588006606,\n",
       "  0.40324963072378145,\n",
       "  2],\n",
       " [0.07176581680830971,\n",
       "  0.14669421487603287,\n",
       "  0.19056261343012626,\n",
       "  0.15596846846846857,\n",
       "  0.027084818246614573,\n",
       "  0.464431991054363,\n",
       "  0.3018217626784833,\n",
       "  2],\n",
       " [0.06137865911237019,\n",
       "  0.12190082644628096,\n",
       "  0.25226860254083433,\n",
       "  0.10754504504504496,\n",
       "  0.06058446186742689,\n",
       "  0.3583325748611996,\n",
       "  0.2801575578532743,\n",
       "  2],\n",
       " [0.040604343720491,\n",
       "  0.12190082644628096,\n",
       "  0.09800362976406465,\n",
       "  0.23986486486486497,\n",
       "  0.05060584461867438,\n",
       "  0.7762290499161347,\n",
       "  0.3170851797144265,\n",
       "  2],\n",
       " [0.09065155807365448,\n",
       "  0.1425619834710743,\n",
       "  0.3393829401088929,\n",
       "  0.1509009009009008,\n",
       "  0.15324305060584478,\n",
       "  0.7736285740290474,\n",
       "  0.21516494337764666,\n",
       "  2],\n",
       " [0.06421152030217184,\n",
       "  0.11570247933884308,\n",
       "  0.3067150635208707,\n",
       "  0.10641891891891896,\n",
       "  0.09479686386315037,\n",
       "  0.4607913248124408,\n",
       "  0.23682914820285572,\n",
       "  2],\n",
       " [0.07648725212464594,\n",
       "  0.13842975206611569,\n",
       "  0.26678765880217775,\n",
       "  0.13344594594594603,\n",
       "  0.09479686386315037,\n",
       "  0.6270917577916759,\n",
       "  0.2806499261447565,\n",
       "  2],\n",
       " [0.02266288951841362,\n",
       "  0.11363636363636379,\n",
       "  0.016333938294010104,\n",
       "  0.21340090090090066,\n",
       "  0.007840342124020041,\n",
       "  0.574302097283803,\n",
       "  0.3279172821270308,\n",
       "  2],\n",
       " [0.019830028328611977,\n",
       "  0.03305785123966945,\n",
       "  0.4618874773139742,\n",
       "  0.046171171171171095,\n",
       "  0.13613684960798306,\n",
       "  0.5211223653928668,\n",
       "  0.26784835056622336,\n",
       "  2],\n",
       " [0.06326723323890462,\n",
       "  0.12396694214876026,\n",
       "  0.248638838475499,\n",
       "  0.16159909909909909,\n",
       "  0.05702066999287245,\n",
       "  0.5941957378200211,\n",
       "  0.28212703101920217,\n",
       "  2],\n",
       " [0.014164305949008532,\n",
       "  0.0661157024793389,\n",
       "  0.22504537205081615,\n",
       "  0.13851351351351326,\n",
       "  0.008553100498930866,\n",
       "  0.5118906759937069,\n",
       "  0.21861152141802068,\n",
       "  2],\n",
       " [0.08404154863078381,\n",
       "  0.1322314049586778,\n",
       "  0.35571687840290406,\n",
       "  0.15822072072072058,\n",
       "  0.09123307198859591,\n",
       "  0.6645386105657336,\n",
       "  0.23781388478581966,\n",
       "  2],\n",
       " [0.15297450424929188,\n",
       "  0.21900826446281002,\n",
       "  0.33756805807622525,\n",
       "  0.257882882882883,\n",
       "  0.18745545260156793,\n",
       "  0.11648831736207728,\n",
       "  0.3244707040866568,\n",
       "  2],\n",
       " [0.07743153918791315,\n",
       "  0.11157024793388412,\n",
       "  0.43466424682395605,\n",
       "  0.10754504504504496,\n",
       "  0.10334996436208123,\n",
       "  0.5450467435540703,\n",
       "  0.15066469719350079,\n",
       "  2],\n",
       " [0.1765816808309727,\n",
       "  0.2066115702479339,\n",
       "  0.5671506352087116,\n",
       "  0.18975225225225212,\n",
       "  0.27583749109052025,\n",
       "  0.5489474573847014,\n",
       "  0.30920728705071404,\n",
       "  2],\n",
       " [0.15108593012275728,\n",
       "  0.19628099173553704,\n",
       "  0.451905626134301,\n",
       "  0.19200450450450463,\n",
       "  0.1988595866001424,\n",
       "  0.5320443641186338,\n",
       "  0.31462333825701644,\n",
       "  2],\n",
       " [0.10009442870632677,\n",
       "  0.1363636363636364,\n",
       "  0.44827586206896564,\n",
       "  0.11768018018017999,\n",
       "  0.15680684248039922,\n",
       "  0.5778127397313708,\n",
       "  0.30329886755292945,\n",
       "  2],\n",
       " [0.2171860245514637,\n",
       "  0.28099173553719,\n",
       "  0.41742286751361113,\n",
       "  0.33558558558558566,\n",
       "  0.2822523164647183,\n",
       "  0.7047159630212328,\n",
       "  0.39241752831117666,\n",
       "  2],\n",
       " [0.09159584513692169,\n",
       "  0.18595041322314057,\n",
       "  0.10617059891107021,\n",
       "  0.26126126126126153,\n",
       "  0.03777619387027792,\n",
       "  0.4286754476069122,\n",
       "  0.3264401772525851,\n",
       "  2],\n",
       " [0.11520302171860251,\n",
       "  0.21487603305785108,\n",
       "  0.10617059891107021,\n",
       "  0.28941441441441457,\n",
       "  0.06129722024233804,\n",
       "  0.5373753396871628,\n",
       "  0.4101427868045299,\n",
       "  2],\n",
       " [0.03021718602455149,\n",
       "  0.08057851239669434,\n",
       "  0.26406533575317626,\n",
       "  0.10641891891891896,\n",
       "  0.03207412687099067,\n",
       "  0.4438882315463731,\n",
       "  0.21516494337764666,\n",
       "  2],\n",
       " [0.06043437204910298,\n",
       "  0.08471074380165293,\n",
       "  0.4655172413793106,\n",
       "  0.10698198198198221,\n",
       "  0.13613684960798306,\n",
       "  0.8788178236617301,\n",
       "  0.2156573116691284,\n",
       "  2],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.514519056261343,\n",
       "  0.0,\n",
       "  0.1119030648610121,\n",
       "  0.547387171852449,\n",
       "  0.13540128015755762,\n",
       "  2],\n",
       " [0.03210576015108592,\n",
       "  0.08057851239669434,\n",
       "  0.28039927404718634,\n",
       "  0.08277027027027041,\n",
       "  0.06200997861724886,\n",
       "  0.6023872368643461,\n",
       "  0.25898572131954695,\n",
       "  2],\n",
       " [0.06421152030217184,\n",
       "  0.0929752066115701,\n",
       "  0.4373865698729576,\n",
       "  0.10810810810810821,\n",
       "  0.12401995723449742,\n",
       "  0.41866361544162584,\n",
       "  0.23732151649433791,\n",
       "  2],\n",
       " [0.12086874409820579,\n",
       "  0.12603305785123955,\n",
       "  0.6479128856624313,\n",
       "  0.13119369369369352,\n",
       "  0.23022095509622226,\n",
       "  0.3682143832321315,\n",
       "  0.3018217626784833,\n",
       "  2],\n",
       " [0.021718602455146407,\n",
       "  0.08677685950413222,\n",
       "  0.1588021778584389,\n",
       "  0.15822072072072058,\n",
       "  0.0,\n",
       "  0.5315242689412162,\n",
       "  0.2806499261447565,\n",
       "  2],\n",
       " [0.14353163361661941,\n",
       "  0.17768595041322302,\n",
       "  0.5063520871143373,\n",
       "  0.18975225225225212,\n",
       "  0.24590163934426235,\n",
       "  0.43777711321171775,\n",
       "  0.24273756770063984,\n",
       "  2],\n",
       " [0.20868744098205863,\n",
       "  0.21900826446281002,\n",
       "  0.7068965517241379,\n",
       "  0.14695945945945954,\n",
       "  0.35352815395580883,\n",
       "  0.5341247448283036,\n",
       "  0.1944854751354011,\n",
       "  2],\n",
       " [0.20774315391879125,\n",
       "  0.2314049586776858,\n",
       "  0.6397459165154268,\n",
       "  0.18299549549549562,\n",
       "  0.3022095509622237,\n",
       "  0.6134392593844673,\n",
       "  0.2161496799606106,\n",
       "  2],\n",
       " [0.2625118035882908,\n",
       "  0.28305785123966926,\n",
       "  0.6969147005444647,\n",
       "  0.23704954954954974,\n",
       "  0.35495367070563083,\n",
       "  0.5077299145743671,\n",
       "  0.2816346627277204,\n",
       "  2],\n",
       " [0.1916902738432483,\n",
       "  0.26033057851239666,\n",
       "  0.36297640653357477,\n",
       "  0.2877252252252253,\n",
       "  0.20028510334996438,\n",
       "  0.33037745907501076,\n",
       "  0.3505662235352043,\n",
       "  2],\n",
       " [0.2049102927289896,\n",
       "  0.200413223140496,\n",
       "  0.8012704174228672,\n",
       "  0.0979729729729732,\n",
       "  0.37419814682822505,\n",
       "  0.2682260853736234,\n",
       "  0.1531265386509109,\n",
       "  2],\n",
       " [0.16902738432483483,\n",
       "  0.21280991735537177,\n",
       "  0.4791288566243192,\n",
       "  0.18018018018018037,\n",
       "  0.2558802565930149,\n",
       "  0.6120089976465694,\n",
       "  0.25898572131954695,\n",
       "  2],\n",
       " [0.19641170915958453,\n",
       "  0.18801652892561987,\n",
       "  0.8130671506352091,\n",
       "  0.04786036036036034,\n",
       "  0.3599429793300069,\n",
       "  0.1995735219545177,\n",
       "  0.11127523387493846,\n",
       "  2],\n",
       " [0.05571293673276675,\n",
       "  0.06404958677685961,\n",
       "  0.5435571687840288,\n",
       "  0.06193693693693712,\n",
       "  0.128296507483963,\n",
       "  0.4272451858690141,\n",
       "  0.15214180206794692,\n",
       "  2],\n",
       " [0.19924457034938617,\n",
       "  0.2066115702479339,\n",
       "  0.7196007259528127,\n",
       "  0.15990990990990983,\n",
       "  0.3285816108339274,\n",
       "  1.0,\n",
       "  0.23682914820285572,\n",
       "  2],\n",
       " [0.16808309726156745,\n",
       "  0.21900826446281002,\n",
       "  0.4410163339382939,\n",
       "  0.1717342342342341,\n",
       "  0.2352102637205987,\n",
       "  0.4100820450142377,\n",
       "  0.23732151649433791,\n",
       "  2],\n",
       " [0.15108593012275728,\n",
       "  0.16322314049586759,\n",
       "  0.6370235934664242,\n",
       "  0.13400900900900878,\n",
       "  0.2501781895937276,\n",
       "  0.37263519224018,\n",
       "  0.17282127031019204,\n",
       "  2],\n",
       " [0.06043437204910298,\n",
       "  0.09710743801652906,\n",
       "  0.39019963702359295,\n",
       "  0.13569819819819803,\n",
       "  0.11760513186029935,\n",
       "  0.46287170552211065,\n",
       "  0.23830625307730186,\n",
       "  2],\n",
       " [0.2464589235127478,\n",
       "  0.2582644628099174,\n",
       "  0.7277676950998182,\n",
       "  0.18975225225225212,\n",
       "  0.429080541696365,\n",
       "  0.9816666449960343,\n",
       "  0.26440177252584934,\n",
       "  2],\n",
       " [0.11803588290840415,\n",
       "  0.16528925619834725,\n",
       "  0.3992740471869323,\n",
       "  0.15540540540540532,\n",
       "  0.1468282252316464,\n",
       "  0.3683444070264859,\n",
       "  0.25849335302806475,\n",
       "  2],\n",
       " [0.16147308781869696,\n",
       "  0.19214876033057846,\n",
       "  0.5471869328493641,\n",
       "  0.19369369369369388,\n",
       "  0.2451888809693515,\n",
       "  0.6334629237150399,\n",
       "  0.26784835056622336,\n",
       "  2]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_dataset(dataset_seed,minmax)\n",
    "dataset_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.440982</td>\n",
       "      <td>0.502066</td>\n",
       "      <td>0.570780</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.486101</td>\n",
       "      <td>0.189302</td>\n",
       "      <td>0.345150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.405099</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>0.662432</td>\n",
       "      <td>0.368806</td>\n",
       "      <td>0.501069</td>\n",
       "      <td>0.032883</td>\n",
       "      <td>0.215165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.349386</td>\n",
       "      <td>0.347107</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.220721</td>\n",
       "      <td>0.503920</td>\n",
       "      <td>0.251453</td>\n",
       "      <td>0.150665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.306893</td>\n",
       "      <td>0.316116</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.239302</td>\n",
       "      <td>0.533856</td>\n",
       "      <td>0.194243</td>\n",
       "      <td>0.140817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.524079</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.864791</td>\n",
       "      <td>0.427365</td>\n",
       "      <td>0.664291</td>\n",
       "      <td>0.076701</td>\n",
       "      <td>0.322994</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.151086</td>\n",
       "      <td>0.163223</td>\n",
       "      <td>0.637024</td>\n",
       "      <td>0.134009</td>\n",
       "      <td>0.250178</td>\n",
       "      <td>0.372635</td>\n",
       "      <td>0.172821</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.060434</td>\n",
       "      <td>0.097107</td>\n",
       "      <td>0.390200</td>\n",
       "      <td>0.135698</td>\n",
       "      <td>0.117605</td>\n",
       "      <td>0.462872</td>\n",
       "      <td>0.238306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.246459</td>\n",
       "      <td>0.258264</td>\n",
       "      <td>0.727768</td>\n",
       "      <td>0.189752</td>\n",
       "      <td>0.429081</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.264402</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.118036</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>0.399274</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.146828</td>\n",
       "      <td>0.368344</td>\n",
       "      <td>0.258493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.161473</td>\n",
       "      <td>0.192149</td>\n",
       "      <td>0.547187</td>\n",
       "      <td>0.193694</td>\n",
       "      <td>0.245189</td>\n",
       "      <td>0.633463</td>\n",
       "      <td>0.267848</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  7\n",
       "0    0.440982  0.502066  0.570780  0.486486  0.486101  0.189302  0.345150  0\n",
       "1    0.405099  0.446281  0.662432  0.368806  0.501069  0.032883  0.215165  0\n",
       "2    0.349386  0.347107  0.879310  0.220721  0.503920  0.251453  0.150665  0\n",
       "3    0.306893  0.316116  0.793103  0.239302  0.533856  0.194243  0.140817  0\n",
       "4    0.524079  0.533058  0.864791  0.427365  0.664291  0.076701  0.322994  0\n",
       "..        ...       ...       ...       ...       ...       ...       ... ..\n",
       "205  0.151086  0.163223  0.637024  0.134009  0.250178  0.372635  0.172821  2\n",
       "206  0.060434  0.097107  0.390200  0.135698  0.117605  0.462872  0.238306  2\n",
       "207  0.246459  0.258264  0.727768  0.189752  0.429081  0.981667  0.264402  2\n",
       "208  0.118036  0.165289  0.399274  0.155405  0.146828  0.368344  0.258493  2\n",
       "209  0.161473  0.192149  0.547187  0.193694  0.245189  0.633463  0.267848  2\n",
       "\n",
       "[210 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame(dataset_seed)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"]\n",
    "df.columns = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df.loc[:,[\"7\"]]\n",
    "X_df= df.loc[:,[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 168 y_train: 168\n",
      "X_test: 42 y_test: 42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df,y_df, test_size = 0.2)\n",
    "\n",
    "print(\"X_train:\",len(X_train),\"y_train:\",len(y_train))\n",
    "print(\"X_test:\",len(X_test),\"y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train).astype(float)\n",
    "X_test= pd.DataFrame(X_test).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.to_numpy()\n",
    "y_test=y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [[j for j in X_train[i]] for i in range(len(X_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    train[i].append(int(y_train[i]))\n",
    "    # print(train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network_dataset( network , train , l_rate , n_epoch , n_outputs ) :\n",
    "    # n_epoch defines number of iterations for the training process\n",
    "    for epoch in range ( n_epoch ) :\n",
    "        sum_error = 0\n",
    "        for row in train :\n",
    "            outputs = forward_propagate(network,row)\n",
    "            \n",
    "            \n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            # print(\"len expected\",len(expected))\n",
    "            # print(\"row\",row)\n",
    "            # print(\"row[-1]\",row[-1])\n",
    "            expected[row[-1]] = 1\n",
    "            # print(\"expected\",expected)\n",
    "        \n",
    "\n",
    "\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            sum_error = sum_error / len(expected)\n",
    "            \n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "            # print ( '>epoch =%d , lrate =%.3f , error =%.3f' %(epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 18 : Initialize a network regarding the dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " In my function initializa_network, there is\n",
      "LAYERS i 7 h 2 o 8\n",
      "[{'weights': [0.859584200402023, 0.707768039517944, 0.2978470231968201, 0.2872580193850891, 0.3246542038821807, 0.9161873451069232, 0.5231991740965767, 0.922402896573605]}, {'weights': [0.27191216810737895, 0.8271631703695481, 0.33819314350469976, 0.8193025775468465, 0.08005061332648389, 0.6448981519319149, 0.30444849094221604, 0.6072253985145525]}]\n",
      "\n",
      "[{'weights': [0.06083278510102852, 0.844523331720227, 0.5008624886025901]}, {'weights': [0.874866089568426, 0.16556682236365894, 0.24166349170619483]}, {'weights': [0.10478526476871586, 0.2987704433373851, 0.8106584619179452]}, {'weights': [0.22993961306981736, 0.3050770383140605, 0.7007597775793108]}, {'weights': [0.40784951767985844, 0.4538563316964077, 0.5070313946774923]}, {'weights': [0.2569962499427999, 0.9682724991399112, 0.8448417635170204]}, {'weights': [0.06579886231058774, 0.2925547205036594, 0.10381071646750673]}, {'weights': [0.42617927985160187, 0.4936974298140252, 0.7387610990155241]}]\n",
      "\n",
      "Network:\n",
      " [[{'weights': [0.859584200402023, 0.707768039517944, 0.2978470231968201, 0.2872580193850891, 0.3246542038821807, 0.9161873451069232, 0.5231991740965767, 0.922402896573605]}, {'weights': [0.27191216810737895, 0.8271631703695481, 0.33819314350469976, 0.8193025775468465, 0.08005061332648389, 0.6448981519319149, 0.30444849094221604, 0.6072253985145525]}], [{'weights': [0.06083278510102852, 0.844523331720227, 0.5008624886025901]}, {'weights': [0.874866089568426, 0.16556682236365894, 0.24166349170619483]}, {'weights': [0.10478526476871586, 0.2987704433373851, 0.8106584619179452]}, {'weights': [0.22993961306981736, 0.3050770383140605, 0.7007597775793108]}, {'weights': [0.40784951767985844, 0.4538563316964077, 0.5070313946774923]}, {'weights': [0.2569962499427999, 0.9682724991399112, 0.8448417635170204]}, {'weights': [0.06579886231058774, 0.2925547205036594, 0.10381071646750673]}, {'weights': [0.42617927985160187, 0.4936974298140252, 0.7387610990155241]}]]\n"
     ]
    }
   ],
   "source": [
    "n_input = len(df.iloc[0])-1\n",
    "n_output = len(set([row[-1] for row in df]))#len(dataset)\n",
    "n_hidden = 2\n",
    "l_rate = 0.5\n",
    "n_epoch = 200\n",
    "print(\"\\n\")\n",
    "\n",
    "Network = initialize_network(n_input,n_hidden,n_output)\n",
    "print(\"Network:\\n\",Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 19: Predict the test set on trained network. Compute the mean square error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_network(Network, train, l_rate, n_epoch, n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [[j for j in X_test[i]] for i in range(len(X_test))]\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i].append(int(y_test[i]))\n",
    "    # print(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 2, 1, 0, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 1, 0, 1, 2, 0, 2, 1, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 1, 2] \n",
      " [1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "listprediction = []\n",
    "listexpected = []\n",
    "for row in X_test:\n",
    "    prediction = predict(Network,row)\n",
    "   \n",
    "    listprediction.append(prediction)\n",
    "    listexpected.append(row[-1])\n",
    "\n",
    "print(listexpected,\"\\n\",listprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error =  0.3333333333333333\n",
      "Accuracy = 66.67 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"Mean squared error = \", mean_squared_error(listexpected,listprediction))\n",
    "accuracy = 0\n",
    "count=0\n",
    "for i in range(len(listexpected)):\n",
    "    if(listexpected[i]==listprediction[i]):\n",
    "        count+=1\n",
    "accuracy = round((count / len(listexpected))*100, 2)\n",
    "print(\"Accuracy =\",accuracy,\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd44577227b4500bd45e9a7c8de683b29d60be5d3ae7bf5644af1d5da89d3012"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
